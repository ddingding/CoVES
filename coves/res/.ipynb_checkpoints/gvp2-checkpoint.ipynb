{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fd448-64f2-49b6-9083-dbac5b25266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend the vanilla gvp with partial charge information, hydrogen atoms. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0cc051-e949-4fcf-a816-d02f994706f3",
   "metadata": {},
   "source": [
    "# get atom3d res dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a467a792-ef02-4604-a975-3a83a2ad71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gvp\n",
    "from atom3d.datasets import LMDBDataset\n",
    "import torch_geometric\n",
    "from functools import partial\n",
    "import gvp.atom3d\n",
    "import torch.nn as nn\n",
    "import tqdm, torch, time, os\n",
    "import numpy as np\n",
    "from atom3d.util import metrics\n",
    "import sklearn.metrics as sk_metrics\n",
    "from collections import defaultdict\n",
    "import scipy.stats as stats\n",
    "print = partial(print, flush=True)\n",
    "\n",
    "models_dir = 'models'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_id = float(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f2bb52-3a0b-4a98-847a-f1b8e0c02fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a72cb037-1c02-4001-8cf2-f34cc47e02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lba_split = 30\n",
    "def get_datasets(task, lba_split=lba_split):\n",
    "    data_path = {\n",
    "        'RES' : '/n/groups/marks/users/david/res/atom3d_data/raw/RES/data/',\n",
    "    }[task]\n",
    "\n",
    "    if task == 'RES':\n",
    "        split_path = '/n/groups/marks/users/david/res/atom3d_data/split-by-cath-topology/indices/'\n",
    "        dataset = partial(gvp.atom3d.RESDataset, data_path)        \n",
    "        trainset = dataset(split_path=split_path+'train_indices.txt')\n",
    "        valset = dataset(split_path=split_path+'val_indices.txt')\n",
    "        testset = dataset(split_path=split_path+'test_indices.txt')\n",
    "\n",
    "\n",
    "    return trainset, valset, testset\n",
    "\n",
    "datasets = get_datasets('RES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7bed52-abec-401d-bdff-b30a94abffd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gvp.atom3d.RESDataset at 0x7fcce5a27d10>,\n",
       " <gvp.atom3d.RESDataset at 0x7fc493920610>,\n",
       " <gvp.atom3d.RESDataset at 0x7fbc430b1e50>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92cb87c7-9b63-40c7-be5e-fd42889c68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8 # control memory of model as long as you can fit a batch size of 1, you can do gradient accumultion to simulate batch size.\n",
    "num_workers = 4\n",
    "dataloader = partial(torch_geometric.data.DataLoader, \n",
    "                    num_workers=num_workers, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2bcfac-ed0f-4292-9c6a-5b658b6937f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "trainset, valset, testset = map(dataloader, datasets)   # apply dataloader to all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a07fe-7b35-4070-8e4c-c09f28489641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does resdataset contain hydrogen atoms? if not, need to model the hydrogens in.\n",
    "# does resdataset contain partial charges?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efc0446a-dbcb-416a-91e5-d09df7d855f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[3916, 3], edge_index=[2, 58980], atoms=[3916], edge_s=[58980, 16], edge_v=[58980, 1, 3], label=[8], ca_idx=[8], batch=[3916], ptr=[9])\n",
      "tensor([[ 9.3440, 49.7340, 34.3500],\n",
      "        [10.5090, 49.7710, 33.4160],\n",
      "        [10.0440, 50.1210, 32.0090],\n",
      "        ...,\n",
      "        [11.1740, 54.1660, 45.0140],\n",
      "        [10.0060, 54.3090, 45.4390],\n",
      "        [11.4360, 53.9010, 43.8220]]) torch.Size([3916, 3])\n",
      "label tensor([ 0, 15,  0, 17, 19,  0, 13,  4])\n",
      "ca_idx tensor([  1,  17,  23,  39,  48, 110, 275, 293])\n",
      "DataBatch(x=[5705, 3], edge_index=[2, 86966], atoms=[5705], edge_s=[86966, 16], edge_v=[86966, 1, 3], label=[8], ca_idx=[8], batch=[5705], ptr=[9])\n",
      "tensor([[ 30.3090,  18.2370,  10.0200],\n",
      "        [ 28.8510,  18.1110,   9.7240],\n",
      "        [ 28.0360,  18.1700,  11.0140],\n",
      "        ...,\n",
      "        [  6.4770,  -8.7310,  13.6180],\n",
      "        [  8.4440, -10.8350,  12.4890],\n",
      "        [  5.6950, -28.5240,  12.3890]]) torch.Size([5705, 3])\n",
      "label tensor([14, 12,  0,  8,  1, 19,  8, 14])\n",
      "ca_idx tensor([ 11,  73,  77, 110, 114, 161,  70,  97])\n",
      "DataBatch(x=[3801, 3], edge_index=[2, 61628], atoms=[3801], edge_s=[61628, 16], edge_v=[61628, 1, 3], label=[8], ca_idx=[8], batch=[3801], ptr=[9])\n",
      "tensor([[ 4.4000, 10.5710,  1.4090],\n",
      "        [ 3.3550, 10.6900,  0.8100],\n",
      "        [ 4.7140, 12.9140,  1.2750],\n",
      "        ...,\n",
      "        [-5.9570, 17.1280,  3.1210],\n",
      "        [-3.4490, 13.6260,  6.4830],\n",
      "        [-4.5730, 11.9600,  8.4810]]) torch.Size([3801, 3])\n",
      "label tensor([13,  8, 18, 10, 16,  5, 10, 11])\n",
      "ca_idx tensor([ 73,  77,  82, 133, 136, 181, 206, 150])\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for b in trainset:\n",
    "    print(b)\n",
    "    print(b.x,b.x.shape)\n",
    "    print('label',b.label)\n",
    "    print('ca_idx',b.ca_idx)\n",
    "    c+=1\n",
    "    if c>2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1d25441-c04e-46e7-8eb4-1f1f3cd34be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from atom3d.datasets import LMDBDataset\n",
    "#import atom3d.datasets.ppi.neighbors as nb\n",
    "from torch.utils.data import IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c5c6002-efee-49ca-b11a-c36ad00889ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/atom3d-0.2.4-py3.7.egg/atom3d']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import atom3d\n",
    "atom3d.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16372c4f-2c53-4c7d-8f5f-d77af082244e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/atom3d-0.2.4-py3.7.egg/atom3d/datasets']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import atom3d.datasets\n",
    "atom3d.datasets.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97804a19-56ae-431e-8131-77432e367df1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LMDBDataset' object has no attribute '__keys__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-716ba9d917e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLMDBDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/n/groups/marks/users/david/res/atom3d_data/raw/RES/data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__keys__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LMDBDataset' object has no attribute '__keys__'"
     ]
    }
   ],
   "source": [
    "ds = LMDBDataset('/n/groups/marks/users/david/res/atom3d_data/raw/RES/data/')\n",
    "ds.__keys__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e052cc0-8ee8-4900-b451-f1206217418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_NUM_ATOM_TYPES = 9\n",
    "_element_mapping = lambda x: {\n",
    "    'H' : 0,\n",
    "    'C' : 1,\n",
    "    'N' : 2,\n",
    "    'O' : 3,\n",
    "    'F' : 4,\n",
    "    'S' : 5,\n",
    "    'Cl': 6, 'CL': 6,\n",
    "    'P' : 7\n",
    "}.get(x, 8)\n",
    "_amino_acids = lambda x: {\n",
    "    'ALA': 0,\n",
    "    'ARG': 1,\n",
    "    'ASN': 2,\n",
    "    'ASP': 3,\n",
    "    'CYS': 4,\n",
    "    'GLU': 5,\n",
    "    'GLN': 6,\n",
    "    'GLY': 7,\n",
    "    'HIS': 8,\n",
    "    'ILE': 9,\n",
    "    'LEU': 10,\n",
    "    'LYS': 11,\n",
    "    'MET': 12,\n",
    "    'PHE': 13,\n",
    "    'PRO': 14,\n",
    "    'SER': 15,\n",
    "    'THR': 16,\n",
    "    'TRP': 17,\n",
    "    'TYR': 18,\n",
    "    'VAL': 19\n",
    "}.get(x, 20)\n",
    "_DEFAULT_V_DIM = (100, 16)\n",
    "_DEFAULT_E_DIM = (32, 1)\n",
    "\n",
    "\n",
    "def _normalize(tensor, dim=-1):\n",
    "    '''\n",
    "    Normalizes a `torch.Tensor` along dimension `dim` without `nan`s.\n",
    "    '''\n",
    "    return torch.nan_to_num(\n",
    "        torch.div(tensor, torch.norm(tensor, dim=dim, keepdim=True)))\n",
    "\n",
    "\n",
    "def _rbf(D, D_min=0., D_max=20., D_count=16, device='cpu'):\n",
    "    '''\n",
    "    From https://github.com/jingraham/neurips19-graph-protein-design\n",
    "    \n",
    "    Returns an RBF embedding of `torch.Tensor` `D` along a new axis=-1.\n",
    "    That is, if `D` has shape [...dims], then the returned tensor will have\n",
    "    shape [...dims, D_count].\n",
    "    '''\n",
    "    D_mu = torch.linspace(D_min, D_max, D_count, device=device)\n",
    "    D_mu = D_mu.view([1, -1])\n",
    "    D_sigma = (D_max - D_min) / D_count\n",
    "    D_expand = torch.unsqueeze(D, -1)\n",
    "\n",
    "    RBF = torch.exp(-((D_expand - D_mu) / D_sigma) ** 2)\n",
    "    return RBF\n",
    "\n",
    "def _edge_features(coords, edge_index, D_max=4.5, num_rbf=16, device='cpu'):\n",
    "    \n",
    "    E_vectors = coords[edge_index[0]] - coords[edge_index[1]]\n",
    "    rbf = _rbf(E_vectors.norm(dim=-1), \n",
    "               D_max=D_max, D_count=num_rbf, device=device)\n",
    "\n",
    "    edge_s = rbf\n",
    "    edge_v = _normalize(E_vectors).unsqueeze(-2)\n",
    "\n",
    "    edge_s, edge_v = map(torch.nan_to_num,\n",
    "            (edge_s, edge_v))\n",
    "\n",
    "    return edge_s, edge_v\n",
    "\n",
    "class BaseTransform:\n",
    "    '''\n",
    "    Implementation of an ATOM3D Transform which featurizes the atomic\n",
    "    coordinates in an ATOM3D dataframes into `torch_geometric.data.Data`\n",
    "    graphs. This class should not be used directly; instead, use the\n",
    "    task-specific transforms, which all extend BaseTransform. Node\n",
    "    and edge features are as described in the EGNN manuscript.\n",
    "    \n",
    "    Returned graphs have the following attributes:\n",
    "    -x          atomic coordinates, shape [n_nodes, 3]\n",
    "    -atoms      numeric encoding of atomic identity, shape [n_nodes]\n",
    "    -edge_index edge indices, shape [2, n_edges]\n",
    "    -edge_s     edge scalar features, shape [n_edges, 16]\n",
    "    -edge_v     edge scalar features, shape [n_edges, 1, 3]\n",
    "    \n",
    "    Subclasses of BaseTransform will produce graphs with additional \n",
    "    attributes for the tasks-specific training labels, in addition \n",
    "    to the above.\n",
    "    \n",
    "    All subclasses of BaseTransform directly inherit the BaseTransform\n",
    "    constructor.\n",
    "    \n",
    "    :param edge_cutoff: distance cutoff to use when drawing edges\n",
    "    :param num_rbf: number of radial bases to encode the distance on each edge\n",
    "    :device: if \"cuda\", will do preprocessing on the GPU\n",
    "    '''\n",
    "    def __init__(self, edge_cutoff=4.5, num_rbf=16, device='cpu'):\n",
    "        self.edge_cutoff = edge_cutoff\n",
    "        self.num_rbf = num_rbf\n",
    "        self.device = device\n",
    "            \n",
    "    def __call__(self, df):\n",
    "        '''\n",
    "        :param df: `pandas.DataFrame` of atomic coordinates\n",
    "                    in the ATOM3D format\n",
    "        \n",
    "        :return: `torch_geometric.data.Data` structure graph\n",
    "        '''\n",
    "        with torch.no_grad():\n",
    "            coords = torch.as_tensor(df[['x', 'y', 'z']].to_numpy(),\n",
    "                                     dtype=torch.float32, device=self.device)\n",
    "            atoms = torch.as_tensor(list(map(_element_mapping, df.element)),\n",
    "                                            dtype=torch.long, device=self.device)\n",
    "\n",
    "            edge_index = torch_cluster.radius_graph(coords, r=self.edge_cutoff)\n",
    "\n",
    "            edge_s, edge_v = _edge_features(coords, edge_index, \n",
    "                                D_max=self.edge_cutoff, num_rbf=self.num_rbf, device=self.device)\n",
    "\n",
    "            return torch_geometric.data.Data(x=coords, atoms=atoms,\n",
    "                        edge_index=edge_index, edge_s=edge_s, edge_v=edge_v)\n",
    "\n",
    "class RESDataset(IterableDataset):\n",
    "    '''\n",
    "    A `torch.utils.data.IterableDataset` wrapper around a\n",
    "    ATOM3D RES dataset.\n",
    "    \n",
    "    On each iteration, returns a `torch_geometric.data.Data`\n",
    "    graph with the attribute `label` encoding the masked residue\n",
    "    identity, `ca_idx` for the node index of the alpha carbon, \n",
    "    and all structural attributes as described in BaseTransform.\n",
    "    \n",
    "    Excludes hydrogen atoms.\n",
    "    \n",
    "    :param lmdb_dataset: path to ATOM3D dataset\n",
    "    :param split_path: path to the ATOM3D split file\n",
    "    '''\n",
    "    def __init__(self, lmdb_dataset, split_path):\n",
    "        self.dataset = LMDBDataset(lmdb_dataset)\n",
    "        self.idx = list(map(int, open(split_path).read().split()))\n",
    "        self.transform = BaseTransform()\n",
    "        \n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        if worker_info is None:\n",
    "            gen = self._dataset_generator(list(range(len(self.idx))), \n",
    "                      shuffle=True)\n",
    "        else:  \n",
    "            per_worker = int(math.ceil(len(self.idx) / float(worker_info.num_workers)))\n",
    "            worker_id = worker_info.id\n",
    "            iter_start = worker_id * per_worker\n",
    "            iter_end = min(iter_start + per_worker, len(self.idx))\n",
    "            gen = self._dataset_generator(list(range(len(self.idx)))[iter_start:iter_end],\n",
    "                      shuffle=True)\n",
    "        return gen\n",
    "    \n",
    "    def _dataset_generator(self, indices, shuffle=True):\n",
    "        if shuffle: random.shuffle(indices)\n",
    "        with torch.no_grad(): # Disabling gradient calculation is useful for inference, when you are sure that you will not call Tensor.backward(). It will reduce memory consumption for computations that would otherwise have requires_grad=True.\n",
    "            for idx in indices:\n",
    "                data = self.dataset[self.idx[idx]]\n",
    "                atoms = data['atoms']\n",
    "                for sub in data['labels'].itertuples():\n",
    "                    _, num, aa = sub.subunit.split('_')\n",
    "                    num, aa = int(num), _amino_acids(aa)\n",
    "                    if aa == 20: continue\n",
    "                    my_atoms = atoms.iloc[data['subunit_indices'][sub.Index]].reset_index(drop=True)\n",
    "                    ca_idx = np.where((my_atoms.residue == num) & (my_atoms.name == 'CA'))[0]\n",
    "                    if len(ca_idx) != 1: continue\n",
    "                        \n",
    "                    with torch.no_grad():\n",
    "                        graph = self.transform(my_atoms)\n",
    "                        graph.label = aa\n",
    "                        graph.ca_idx = int(ca_idx)\n",
    "                        yield graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5eb88-f69c-4086-a8ea-57d65ca5e6ec",
   "metadata": {},
   "source": [
    "# model stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07fb2b51-3717-43a6-907d-784adb627f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(task):\n",
    "    return {\n",
    "        'RES' : gvp.atom3d.RESModel,\n",
    "    }[task]()\n",
    "\n",
    "model = get_model('RES').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd0f37c-2572-4940-bef8-c0cf9e586572",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "parser.add_argument('--num-workers', metavar='N', type=int, default=4,\n",
    "                   help='number of threads for loading data, default=4')\n",
    "parser.add_argument('--smp-idx', metavar='IDX', type=int, default=None,\n",
    "                   choices=list(range(20)),\n",
    "                   help='label index for SMP, in range 0-19')\n",
    "parser.add_argument('--lba-split', metavar='SPLIT', type=int, choices=[30, 60],\n",
    "                    help='identity cutoff for LBA, 30 (default) or 60', default=30)\n",
    "parser.add_argument('--batch', metavar='SIZE', type=int, default=8,\n",
    "                    help='batch size, default=8')\n",
    "parser.add_argument('--train-time', metavar='MINUTES', type=int, default=120,\n",
    "                    help='maximum time between evaluations on valset, default=120 minutes')\n",
    "parser.add_argument('--val-time', metavar='MINUTES', type=int, default=20,\n",
    "                    help='maximum time per evaluation on valset, default=20 minutes')\n",
    "parser.add_argument('--epochs', metavar='N', type=int, default=50,\n",
    "                    help='training epochs, default=50')\n",
    "parser.add_argument('--test', metavar='PATH', default=None,\n",
    "                    help='evaluate a trained model')\n",
    "parser.add_argument('--lr', metavar='RATE', default=1e-4, type=float,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--load', metavar='PATH', default=None, \n",
    "                    help='initialize first 2 GNN layers with pretrained weights')\n",
    "'''\n",
    "\n",
    "lr = 1e-4\n",
    "epochs = 50\n",
    "train_time = 120\n",
    "val_time = 20\n",
    "model_save_path = '/n/groups/marks/users/david/res/model_save/'\n",
    "smp_idx = None\n",
    "\n",
    "\n",
    "def get_label(batch, task, smp_idx=None):\n",
    "    if type(batch) in [list, tuple]: batch = batch[0]\n",
    "    if task == 'SMP':\n",
    "        assert smp_idx is not None\n",
    "        return batch.label[smp_idx::20]\n",
    "    return batch.label\n",
    "\n",
    "def forward(model, batch, device):\n",
    "    if type(batch) in [list, tuple]:\n",
    "        batch = batch[0].to(device), batch[1].to(device)\n",
    "    else:\n",
    "        batch = batch.to(device)\n",
    "    return model(batch)\n",
    "\n",
    "def loop(dataset, model, optimizer=None, max_time=None):\n",
    "    start = time.time()\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    t = tqdm.tqdm(dataset)\n",
    "    total_loss, total_count = 0, 0\n",
    "    \n",
    "    for batch in t:\n",
    "        if max_time and (time.time() - start) > 60*max_time: break\n",
    "        if optimizer: optimizer.zero_grad()\n",
    "        try:\n",
    "            out = forward(model, batch, device)\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA out of memory\" not in str(e): raise(e)\n",
    "            torch.cuda.empty_cache()\n",
    "            print('Skipped batch due to OOM', flush=True)\n",
    "            continue\n",
    "            \n",
    "        label = get_label(batch, 'RES', smp_idx)\n",
    "        loss_value = loss_fn(out, label)\n",
    "        total_loss += float(loss_value)\n",
    "        total_count += 1\n",
    "        \n",
    "        if optimizer:\n",
    "            try:\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "            except RuntimeError as e:\n",
    "                if \"CUDA out of memory\" not in str(e): raise(e)\n",
    "                torch.cuda.empty_cache()\n",
    "                print('Skipped batch due to OOM', flush=True)\n",
    "                continue\n",
    "            \n",
    "        t.set_description(f\"{total_loss/total_count:.8f}\")\n",
    "        \n",
    "    return total_loss / total_count\n",
    "\n",
    "def train(model, trainset, valset):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_path, best_val = None, np.inf\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss = loop(trainset, model, optimizer=optimizer, max_time=train_time)\n",
    "        path = f\"{model_save_path}/RES_{model_id}_{epoch}.pt\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f'\\nEPOCH {epoch} TRAIN loss: {loss:.8f}')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = loop(valset, model, max_time=val_time)\n",
    "        print(f'\\nEPOCH {epoch} VAL loss: {loss:.8f}')\n",
    "        if loss < best_val:\n",
    "            best_path, best_val = path, loss\n",
    "        print(f'BEST {best_path} VAL loss: {best_val:.8f}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f60766-4969-43cc-87ff-c35f8f6082fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.99179641: : 2541it [15:03,  2.81it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fd33defe5697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-97b16448d668>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainset, valset)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{model_save_path}/RES_{model_id}_{epoch}.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-97b16448d668>\u001b[0m in \u001b[0;36mloop\u001b[0;34m(dataset, model, optimizer, max_time)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA out of memory\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-97b16448d668>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, batch, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/users/david/res/gvp-pytorch/gvp/atom3d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    634\u001b[0m         )\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscatter_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/users/david/res/gvp-pytorch/gvp/atom3d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, scatter_mean, dense)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mh_V\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_V\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_E\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_V\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/users/david/res/gvp-pytorch/gvp/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, autoregressive_x, node_mask)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/users/david/res/gvp-pytorch/gvp/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    266\u001b[0m         message = self.propagate(edge_index, \n\u001b[1;32m    267\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                     edge_attr=edge_attr)\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                         \u001b[0maggr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             return scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n\u001b[0;32m--> 386\u001b[0;31m                            reduce=self.aggr)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage_and_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_t\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter_mean\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, trainset, valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72f5559d-4b2c-4b8d-b8a4-187a9a6e16de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--num-workers N] [--smp-idx IDX]\n",
      "                             [--lba-split SPLIT] [--batch SIZE]\n",
      "                             [--train-time MINUTES] [--val-time MINUTES]\n",
      "                             [--epochs N] [--test PATH] [--lr RATE]\n",
      "                             [--load PATH]\n",
      "                             TASK\n",
      "ipykernel_launcher.py: error: argument TASK: invalid choice: '/home/dd128/.local/share/jupyter/runtime/kernel-970b75c3-b998-4365-a189-164295414e77.json' (choose from 'PSR', 'RSR', 'PPI', 'RES', 'MSP', 'SMP', 'LBA', 'LEP')\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1787, in parse_known_args\n",
      "    namespace, args = self._parse_known_args(args, namespace)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1996, in _parse_known_args\n",
      "    stop_index = consume_positionals(start_index)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1952, in consume_positionals\n",
      "    take_action(action, args)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1845, in take_action\n",
      "    argument_values = self._get_values(action, argument_strings)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 2377, in _get_values\n",
      "    self._check_value(action, value)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 2433, in _check_value\n",
      "    raise ArgumentError(action, msg % args)\n",
      "argparse.ArgumentError: argument TASK: invalid choice: '/home/dd128/.local/share/jupyter/runtime/kernel-970b75c3-b998-4365-a189-164295414e77.json' (choose from 'PSR', 'RSR', 'PPI', 'RES', 'MSP', 'SMP', 'LBA', 'LEP')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-79f9289d065f>\", line 29, in <module>\n",
      "    args = parser.parse_args()\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1755, in parse_args\n",
      "    args, argv = self.parse_known_args(args, namespace)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1794, in parse_known_args\n",
      "    self.error(str(err))\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 2508, in error\n",
      "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 2495, in exit\n",
      "    _sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_UNRECOGNIZED_ARGS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   1995\u001b[0m         \u001b[0;31m# consume any positionals following the last Optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1996\u001b[0;31m         \u001b[0mstop_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsume_positionals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mconsume_positionals\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   1951\u001b[0m                 \u001b[0mstart_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0marg_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m                 \u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mtake_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mseen_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1845\u001b[0;31m             \u001b[0margument_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margument_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2376\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36m_check_value\u001b[0;34m(self, action, value)\u001b[0m\n\u001b[1;32m   2432\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid choice: %(value)r (choose from %(choices)s)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2433\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument TASK: invalid choice: '/home/dd128/.local/share/jupyter/runtime/kernel-970b75c3-b998-4365-a189-164295414e77.json' (choose from 'PSR', 'RSR', 'PPI', 'RES', 'MSP', 'SMP', 'LBA', 'LEP')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-79f9289d065f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1793\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2507\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2495\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2053\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m   2054\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0;32m-> 2055\u001b[0;31m                                                                      value))\n\u001b[0m\u001b[1;32m   2056\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[1;32m    632\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                 + out_list)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# from gvp-pytorch: run_atom3d.py\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('task', metavar='TASK', choices=[\n",
    "        'PSR', 'RSR', 'PPI', 'RES', 'MSP', 'SMP', 'LBA', 'LEP'\n",
    "    ], help=\"{PSR, RSR, PPI, RES, MSP, SMP, LBA, LEP}\")\n",
    "parser.add_argument('--num-workers', metavar='N', type=int, default=4,\n",
    "                   help='number of threads for loading data, default=4')\n",
    "parser.add_argument('--smp-idx', metavar='IDX', type=int, default=None,\n",
    "                   choices=list(range(20)),\n",
    "                   help='label index for SMP, in range 0-19')\n",
    "parser.add_argument('--lba-split', metavar='SPLIT', type=int, choices=[30, 60],\n",
    "                    help='identity cutoff for LBA, 30 (default) or 60', default=30)\n",
    "parser.add_argument('--batch', metavar='SIZE', type=int, default=8,\n",
    "                    help='batch size, default=8')\n",
    "parser.add_argument('--train-time', metavar='MINUTES', type=int, default=120,\n",
    "                    help='maximum time between evaluations on valset, default=120 minutes')\n",
    "parser.add_argument('--val-time', metavar='MINUTES', type=int, default=20,\n",
    "                    help='maximum time per evaluation on valset, default=20 minutes')\n",
    "parser.add_argument('--epochs', metavar='N', type=int, default=50,\n",
    "                    help='training epochs, default=50')\n",
    "parser.add_argument('--test', metavar='PATH', default=None,\n",
    "                    help='evaluate a trained model')\n",
    "parser.add_argument('--lr', metavar='RATE', default=1e-4, type=float,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--load', metavar='PATH', default=None, \n",
    "                    help='initialize first 2 GNN layers with pretrained weights')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    datasets = get_datasets(args.task, args.lba_split)\n",
    "    dataloader = partial(torch_geometric.data.DataLoader, \n",
    "                    num_workers=args.num_workers, batch_size=args.batch)\n",
    "    if args.task not in ['PPI', 'RES']:\n",
    "        dataloader = partial(dataloader, shuffle=True)\n",
    "        \n",
    "    trainset, valset, testset = map(dataloader, datasets)    \n",
    "    model = get_model(args.task).to(device)\n",
    "    \n",
    "    if args.test:\n",
    "        test(model, testset)\n",
    "\n",
    "    else:\n",
    "        if args.load:\n",
    "            load(model, args.load)\n",
    "        train(model, trainset, valset)\n",
    "        \n",
    "def test(model, testset):\n",
    "    model.load_state_dict(torch.load(args.test))\n",
    "    model.eval()\n",
    "    t = tqdm.tqdm(testset)\n",
    "    metrics = get_metrics(args.task)\n",
    "    targets, predicts, ids = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in t:\n",
    "            pred = forward(model, batch, device)\n",
    "            label = get_label(batch, args.task, args.smp_idx)\n",
    "            if args.task == 'RES':\n",
    "                pred = pred.argmax(dim=-1)\n",
    "            if args.task in ['PSR', 'RSR']:\n",
    "                ids.extend(batch.id)\n",
    "            targets.extend(list(label.cpu().numpy()))\n",
    "            predicts.extend(list(pred.cpu().numpy()))\n",
    "\n",
    "    for name, func in metrics.items():\n",
    "        if args.task in ['PSR', 'RSR']:\n",
    "            func = partial(func, ids=ids)\n",
    "        value = func(targets, predicts)\n",
    "        print(f\"{name}: {value}\")\n",
    "\n",
    "def train(model, trainset, valset):\n",
    "                                \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    best_path, best_val = None, np.inf\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        loss = loop(trainset, model, optimizer=optimizer, max_time=args.train_time)\n",
    "        path = f\"{models_dir}/{args.task}_{model_id}_{epoch}.pt\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f'\\nEPOCH {epoch} TRAIN loss: {loss:.8f}')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = loop(valset, model, max_time=args.val_time)\n",
    "        print(f'\\nEPOCH {epoch} VAL loss: {loss:.8f}')\n",
    "        if loss < best_val:\n",
    "            best_path, best_val = path, loss\n",
    "        print(f'BEST {best_path} VAL loss: {best_val:.8f}')\n",
    "    \n",
    "def loop(dataset, model, optimizer=None, max_time=None):\n",
    "    start = time.time()\n",
    "    \n",
    "    loss_fn = get_loss(args.task)\n",
    "    t = tqdm.tqdm(dataset)\n",
    "    total_loss, total_count = 0, 0\n",
    "    \n",
    "    for batch in t:\n",
    "        if max_time and (time.time() - start) > 60*max_time: break\n",
    "        if optimizer: optimizer.zero_grad()\n",
    "        try:\n",
    "            out = forward(model, batch, device)\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA out of memory\" not in str(e): raise(e)\n",
    "            torch.cuda.empty_cache()\n",
    "            print('Skipped batch due to OOM', flush=True)\n",
    "            continue\n",
    "            \n",
    "        label = get_label(batch, args.task, args.smp_idx)\n",
    "        loss_value = loss_fn(out, label)\n",
    "        total_loss += float(loss_value)\n",
    "        total_count += 1\n",
    "        \n",
    "        if optimizer:\n",
    "            try:\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "            except RuntimeError as e:\n",
    "                if \"CUDA out of memory\" not in str(e): raise(e)\n",
    "                torch.cuda.empty_cache()\n",
    "                print('Skipped batch due to OOM', flush=True)\n",
    "                continue\n",
    "            \n",
    "        t.set_description(f\"{total_loss/total_count:.8f}\")\n",
    "        \n",
    "    return total_loss / total_count\n",
    "\n",
    "def load(model, path):\n",
    "    params = torch.load(path)\n",
    "    state_dict = model.state_dict()\n",
    "    for name, p in params.items():\n",
    "        if name in state_dict and \\\n",
    "               name[:8] in ['layers.0', 'layers.1'] and \\\n",
    "               state_dict[name].shape == p.shape:\n",
    "            print(\"Loading\", name)\n",
    "            model.state_dict()[name].copy_(p)\n",
    "        \n",
    "#######################################################################\n",
    "\n",
    "def get_label(batch, task, smp_idx=None):\n",
    "    if type(batch) in [list, tuple]: batch = batch[0]\n",
    "    if task == 'SMP':\n",
    "        assert smp_idx is not None\n",
    "        return batch.label[smp_idx::20]\n",
    "    return batch.label\n",
    "\n",
    "def get_metrics(task):\n",
    "    def _correlation(metric, targets, predict, ids=None, glob=True):\n",
    "        if glob: return metric(targets, predict)\n",
    "        _targets, _predict = defaultdict(list), defaultdict(list)\n",
    "        for _t, _p, _id in zip(targets, predict, ids):\n",
    "            _targets[_id].append(_t)\n",
    "            _predict[_id].append(_p)\n",
    "        return np.mean([metric(_targets[_id], _predict[_id]) for _id in _targets])\n",
    "        \n",
    "    correlations = {\n",
    "        'pearson': partial(_correlation, metrics.pearson),\n",
    "        'kendall': partial(_correlation, metrics.kendall),\n",
    "        'spearman': partial(_correlation, metrics.spearman)\n",
    "    }\n",
    "    mean_correlations = {f'mean {k}' : partial(v, glob=False) \\\n",
    "                            for k, v in correlations.items()}\n",
    "    \n",
    "    return {                       \n",
    "        'RSR' : {**correlations, **mean_correlations},\n",
    "        'PSR' : {**correlations, **mean_correlations},\n",
    "        'PPI' : {'auroc': metrics.auroc},\n",
    "        'RES' : {'accuracy': metrics.accuracy},\n",
    "        'MSP' : {'auroc': metrics.auroc, 'auprc': metrics.auprc},\n",
    "        'LEP' : {'auroc': metrics.auroc, 'auprc': metrics.auprc},\n",
    "        'LBA' : {**correlations, 'rmse': partial(sk_metrics.mean_squared_error, squared=False)},\n",
    "        'SMP' : {'mae': sk_metrics.mean_absolute_error}\n",
    "    }[task]\n",
    "            \n",
    "def get_loss(task):\n",
    "    if task in ['PSR', 'RSR', 'SMP', 'LBA']: return nn.MSELoss() # regression\n",
    "    elif task in ['PPI', 'MSP', 'LEP']: return nn.BCELoss() # binary classification\n",
    "    elif task in ['RES']: return nn.CrossEntropyLoss() # multiclass classification\n",
    "    \n",
    "def forward(model, batch, device):\n",
    "    if type(batch) in [list, tuple]:\n",
    "        batch = batch[0].to(device), batch[1].to(device)\n",
    "    else:\n",
    "        batch = batch.to(device)\n",
    "    return model(batch)\n",
    "\n",
    "def get_datasets(task, lba_split=30):\n",
    "    data_path = {\n",
    "        'RES' : 'atom3d-data/RES/raw/RES/data/',\n",
    "        'PPI' : 'atom3d-data/PPI/splits/DIPS-split/data/',\n",
    "        'RSR' : 'atom3d-data/RSR/splits/candidates-split-by-time/data/',\n",
    "        'PSR' : 'atom3d-data/PSR/splits/split-by-year/data/',\n",
    "        'MSP' : 'atom3d-data/MSP/splits/split-by-sequence-identity-30/data/',\n",
    "        'LEP' : 'atom3d-data/LEP/splits/split-by-protein/data/',\n",
    "        'LBA' : f'atom3d-data/LBA/splits/split-by-sequence-identity-{lba_split}/data/',\n",
    "        'SMP' : 'atom3d-data/SMP/splits/random/data/'\n",
    "    }[task]\n",
    "        \n",
    "    if task == 'RES':\n",
    "        split_path = 'atom3d-data/RES/splits/split-by-cath-topology/indices/'\n",
    "        dataset = partial(gvp.atom3d.RESDataset, data_path)        \n",
    "        trainset = dataset(split_path=split_path+'train_indices.txt')\n",
    "        valset = dataset(split_path=split_path+'val_indices.txt')\n",
    "        testset = dataset(split_path=split_path+'test_indices.txt')\n",
    "    \n",
    "    elif task == 'PPI':\n",
    "        trainset = gvp.atom3d.PPIDataset(data_path+'train')\n",
    "        valset = gvp.atom3d.PPIDataset(data_path+'val')\n",
    "        testset = gvp.atom3d.PPIDataset(data_path+'test')\n",
    "        \n",
    "    else:\n",
    "        transform = {                       \n",
    "            'RSR' : gvp.atom3d.RSRTransform,\n",
    "            'PSR' : gvp.atom3d.PSRTransform,\n",
    "            'MSP' : gvp.atom3d.MSPTransform,\n",
    "            'LEP' : gvp.atom3d.LEPTransform,\n",
    "            'LBA' : gvp.atom3d.LBATransform,\n",
    "            'SMP' : gvp.atom3d.SMPTransform,\n",
    "        }[task]()\n",
    "        \n",
    "        trainset = LMDBDataset(data_path+'train', transform=transform)\n",
    "        valset = LMDBDataset(data_path+'val', transform=transform)\n",
    "        testset = LMDBDataset(data_path+'test', transform=transform)\n",
    "        \n",
    "    return trainset, valset, testset\n",
    "\n",
    "def get_model(task):\n",
    "    return {\n",
    "        'RES' : gvp.atom3d.RESModel,\n",
    "    }[task]()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a04fc-7118-4ab2-8732-c9f60a8b684d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

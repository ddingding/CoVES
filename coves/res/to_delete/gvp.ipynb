{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fd448-64f2-49b6-9083-dbac5b25266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gvp: implement gvp on pdb dataset for residue analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692378d4-38eb-41fd-b48c-59f0685d9dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import AA3_TO_AA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b258dd-cfb5-469c-b190-f45b352dc72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdbHelper import get_atoms_neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be8a5419-97ee-4113-b270-4ccf8eb43d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from gvp import GVP, GVPConvLayer, LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f3dea78-247e-4dfd-ac4e-53f4b7704d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gvp.GVP"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03c145a2-0680-401a-858f-5d19920de42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0cc051-e949-4fcf-a816-d02f994706f3",
   "metadata": {},
   "source": [
    "# get atom3d res dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a467a792-ef02-4604-a975-3a83a2ad71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gvp\n",
    "from atom3d.datasets import LMDBDataset\n",
    "import torch_geometric\n",
    "from functools import partial\n",
    "import gvp.atom3d\n",
    "import torch.nn as nn\n",
    "import tqdm, torch, time, os\n",
    "import numpy as np\n",
    "from atom3d.util import metrics\n",
    "import sklearn.metrics as sk_metrics\n",
    "from collections import defaultdict\n",
    "import scipy.stats as stats\n",
    "print = partial(print, flush=True)\n",
    "\n",
    "models_dir = 'models'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_id = float(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f2bb52-3a0b-4a98-847a-f1b8e0c02fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a72cb037-1c02-4001-8cf2-f34cc47e02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lba_split = 30\n",
    "def get_datasets(task, lba_split=lba_split):\n",
    "    data_path = {\n",
    "        'RES' : '/n/groups/marks/users/david/res/atom3d_data/raw/RES/data/',\n",
    "    }[task]\n",
    "\n",
    "    if task == 'RES':\n",
    "        split_path = '/n/groups/marks/users/david/res/atom3d_data/split-by-cath-topology/indices/'\n",
    "        dataset = partial(gvp.atom3d.RESDataset, data_path)        \n",
    "        trainset = dataset(split_path=split_path+'train_indices.txt')\n",
    "        valset = dataset(split_path=split_path+'val_indices.txt')\n",
    "        testset = dataset(split_path=split_path+'test_indices.txt')\n",
    "\n",
    "\n",
    "    return trainset, valset, testset\n",
    "\n",
    "datasets = get_datasets('RES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee7bed52-abec-401d-bdff-b30a94abffd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gvp.atom3d.RESDataset at 0x7f09142c21d0>,\n",
       " <gvp.atom3d.RESDataset at 0x7f08ec207250>,\n",
       " <gvp.atom3d.RESDataset at 0x7f08ccb5ca90>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92cb87c7-9b63-40c7-be5e-fd42889c68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1 # control memory of model as long as you can fit a batch size of 1, you can do gradient accumultion to simulate batch size.\n",
    "num_workers = 4\n",
    "dataloader = partial(torch_geometric.data.DataLoader, \n",
    "                    num_workers=num_workers, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2bcfac-ed0f-4292-9c6a-5b658b6937f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "trainset, valset, testset = map(dataloader, datasets)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2a344-8f9e-45ec-a334-b806df0205e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to create a DataBatch with the following attributes:\n",
    "(x=[531, 3], # xyz of each atom\n",
    "edge_index=[2, 8336], # connections between each atom\n",
    " atoms=[531], # [2, 1, 1, 3, 1, 2, 1, 1, ], presumably codes for which atom it is\n",
    " edge_s=[8336, 16], # edge scalar features, 16 numbers for each atom\n",
    " edge_v=[8336, 1, 3], # edge vectors for each edge\n",
    " label=[1], # just the amino acid label\n",
    " ca_idx=[1], # just says [1], or [16].presumably theindex\n",
    " batch=[531], #just all indicates atoms which belong to one batch [0, *len(atoms)\n",
    " ptr=[2], #tensor([0,531]) # not sure what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3508ab45-6881-46ba-b8ea-d61a71a1d16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[452, 3], edge_index=[2, 7012], atoms=[452], edge_s=[7012, 16], edge_v=[7012, 1, 3], label=[1], ca_idx=[1], batch=[452], ptr=[2])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "torch.Size([452])\n",
      "tensor([  0, 452])\n",
      "tensor([0])\n",
      "ca_idx tensor([6])\n",
      "atoms tensor([2, 1, 1, 3, 1, 2, 1, 1, 3, 2, 1, 1, 3, 1, 3, 2, 1, 1, 3, 1, 1, 1, 2, 1,\n",
      "        2, 2, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 3, 1, 1, 3, 2, 2, 1, 1, 3, 1, 1, 1,\n",
      "        1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3, 3, 1, 1, 2, 1, 1, 3, 3, 2, 1, 1,\n",
      "        3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1,\n",
      "        3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1,\n",
      "        3, 1, 1, 3, 3, 2, 1, 1, 3, 1, 1, 1, 3, 2, 2, 1, 1, 3, 2, 1, 1, 3, 1, 1,\n",
      "        1, 1, 1, 1, 1, 3, 2, 1, 1, 3, 1, 3, 2, 1, 1, 3, 1, 3, 2, 3, 3, 1, 1, 3,\n",
      "        2, 1, 1, 3, 1, 3, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1,\n",
      "        1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 1, 1, 3, 3,\n",
      "        2, 1, 1, 3, 1, 3, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 3,\n",
      "        2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 3, 1, 1, 1,\n",
      "        2, 1, 2, 2, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 3, 1, 2, 1, 1,\n",
      "        3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2,\n",
      "        1, 1, 3, 1, 3, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 3, 1, 1,\n",
      "        1, 1, 2, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 3, 2, 1, 1, 3,\n",
      "        1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2,\n",
      "        1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 3, 2, 1, 1, 3, 2, 1, 1, 3, 1, 1, 3, 3, 2,\n",
      "        1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 5, 1, 2, 1, 1, 3, 1, 1, 1, 2, 2,\n",
      "        1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for b in testset:\n",
    "    if c<1:\n",
    "        print(b)\n",
    "        print(b.batch)\n",
    "        print(b.batch.shape)\n",
    "        print(b.ptr)\n",
    "        print(b.label)\n",
    "        print('ca_idx', b.ca_idx)\n",
    "        print('atoms',b.atoms)\n",
    "        #out = forward(model, b, device)\n",
    "        #print(out.shape)\n",
    "        #print(out)\n",
    "        c+=1\n",
    "    else:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd612d-28e9-40d0-bc07-a7ac3138b0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67fef898-41eb-430a-a97a-aebc63b7a855",
   "metadata": {},
   "source": [
    "# start training from beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07fb2b51-3717-43a6-907d-784adb627f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(task):\n",
    "    return {\n",
    "        'RES' : gvp.atom3d.RESModel,\n",
    "    }[task]()\n",
    "\n",
    "model = get_model('RES').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd0f37c-2572-4940-bef8-c0cf9e586572",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "parser.add_argument('--num-workers', metavar='N', type=int, default=4,\n",
    "                   help='number of threads for loading data, default=4')\n",
    "parser.add_argument('--smp-idx', metavar='IDX', type=int, default=None,\n",
    "                   choices=list(range(20)),\n",
    "                   help='label index for SMP, in range 0-19')\n",
    "parser.add_argument('--lba-split', metavar='SPLIT', type=int, choices=[30, 60],\n",
    "                    help='identity cutoff for LBA, 30 (default) or 60', default=30)\n",
    "parser.add_argument('--batch', metavar='SIZE', type=int, default=8,\n",
    "                    help='batch size, default=8')\n",
    "parser.add_argument('--train-time', metavar='MINUTES', type=int, default=120,\n",
    "                    help='maximum time between evaluations on valset, default=120 minutes')\n",
    "parser.add_argument('--val-time', metavar='MINUTES', type=int, default=20,\n",
    "                    help='maximum time per evaluation on valset, default=20 minutes')\n",
    "parser.add_argument('--epochs', metavar='N', type=int, default=50,\n",
    "                    help='training epochs, default=50')\n",
    "parser.add_argument('--test', metavar='PATH', default=None,\n",
    "                    help='evaluate a trained model')\n",
    "parser.add_argument('--lr', metavar='RATE', default=1e-4, type=float,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--load', metavar='PATH', default=None, \n",
    "                    help='initialize first 2 GNN layers with pretrained weights')\n",
    "'''\n",
    "\n",
    "lr = 1e-4\n",
    "epochs = 50\n",
    "train_time = 120\n",
    "val_time = 20\n",
    "model_save_path = '/n/groups/marks/users/david/res/model_save/'\n",
    "smp_idx = None\n",
    "\n",
    "\n",
    "def get_label(batch, task, smp_idx=None):\n",
    "    if type(batch) in [list, tuple]: batch = batch[0]\n",
    "    if task == 'SMP':\n",
    "        assert smp_idx is not None\n",
    "        return batch.label[smp_idx::20]\n",
    "    return batch.label\n",
    "\n",
    "def forward(model, batch, device):\n",
    "    if type(batch) in [list, tuple]:\n",
    "        batch = batch[0].to(device), batch[1].to(device)\n",
    "    else:\n",
    "        batch = batch.to(device)\n",
    "    return model(batch)\n",
    "\n",
    "def loop(dataset, model, optimizer=None, max_time=None):\n",
    "    start = time.time()\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    t = tqdm.tqdm(dataset)\n",
    "    total_loss, total_count = 0, 0\n",
    "    \n",
    "    for batch in t:\n",
    "        if max_time and (time.time() - start) > 60*max_time: break\n",
    "        if optimizer: optimizer.zero_grad()\n",
    "        try:\n",
    "            out = forward(model, batch, device)\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA out of memory\" not in str(e): raise(e)\n",
    "            torch.cuda.empty_cache()\n",
    "            print('Skipped batch due to OOM', flush=True)\n",
    "            continue\n",
    "            \n",
    "        label = get_label(batch, 'RES', smp_idx)\n",
    "        loss_value = loss_fn(out, label)\n",
    "        total_loss += float(loss_value)\n",
    "        total_count += 1\n",
    "        \n",
    "        if optimizer:\n",
    "            try:\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "            except RuntimeError as e:\n",
    "                if \"CUDA out of memory\" not in str(e): raise(e)\n",
    "                torch.cuda.empty_cache()\n",
    "                print('Skipped batch due to OOM', flush=True)\n",
    "                continue\n",
    "            \n",
    "        t.set_description(f\"{total_loss/total_count:.8f}\")\n",
    "        \n",
    "    return total_loss / total_count\n",
    "\n",
    "def train(model, trainset, valset):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_path, best_val = None, np.inf\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss = loop(trainset, model, optimizer=optimizer, max_time=train_time)\n",
    "        path = f\"{model_save_path}/RES_{model_id}_{epoch}.pt\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f'\\nEPOCH {epoch} TRAIN loss: {loss:.8f}')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = loop(valset, model, max_time=val_time)\n",
    "        print(f'\\nEPOCH {epoch} VAL loss: {loss:.8f}')\n",
    "        if loss < best_val:\n",
    "            best_path, best_val = path, loss\n",
    "        print(f'BEST {best_path} VAL loss: {best_val:.8f}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f60766-4969-43cc-87ff-c35f8f6082fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.99179641: : 2541it [15:03,  2.81it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fd33defe5697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-97b16448d668>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainset, valset)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{model_save_path}/RES_{model_id}_{epoch}.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-97b16448d668>\u001b[0m in \u001b[0;36mloop\u001b[0;34m(dataset, model, optimizer, max_time)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA out of memory\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-97b16448d668>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, batch, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/users/david/res/gvp-pytorch/gvp/atom3d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    634\u001b[0m         )\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscatter_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/users/david/res/gvp-pytorch/gvp/atom3d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, scatter_mean, dense)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mh_V\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_V\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_E\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_V\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/users/david/res/gvp-pytorch/gvp/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, autoregressive_x, node_mask)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/users/david/res/gvp-pytorch/gvp/__init__.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    266\u001b[0m         message = self.propagate(edge_index, \n\u001b[1;32m    267\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                     edge_attr=edge_attr)\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                         \u001b[0maggr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             return scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n\u001b[0;32m--> 386\u001b[0;31m                            reduce=self.aggr)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage_and_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_t\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter_mean\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, trainset, valset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30ed97a-c9af-4ade-8f7a-bd4793d7ccf7",
   "metadata": {},
   "source": [
    "# start training from loaded best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e054c71-dbf3-4cbb-aa39-411febfe033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading layers.0.conv.message_func.0.dummy_param\n",
      "Loading layers.0.conv.message_func.0.wh.weight\n",
      "Loading layers.0.conv.message_func.0.ws.weight\n",
      "Loading layers.0.conv.message_func.0.ws.bias\n",
      "Loading layers.0.conv.message_func.0.wv.weight\n",
      "Loading layers.0.conv.message_func.0.wsv.weight\n",
      "Loading layers.0.conv.message_func.0.wsv.bias\n",
      "Loading layers.0.conv.message_func.1.dummy_param\n",
      "Loading layers.0.conv.message_func.1.wh.weight\n",
      "Loading layers.0.conv.message_func.1.ws.weight\n",
      "Loading layers.0.conv.message_func.1.ws.bias\n",
      "Loading layers.0.conv.message_func.1.wv.weight\n",
      "Loading layers.0.conv.message_func.1.wsv.weight\n",
      "Loading layers.0.conv.message_func.1.wsv.bias\n",
      "Loading layers.0.conv.message_func.2.dummy_param\n",
      "Loading layers.0.conv.message_func.2.wh.weight\n",
      "Loading layers.0.conv.message_func.2.ws.weight\n",
      "Loading layers.0.conv.message_func.2.ws.bias\n",
      "Loading layers.0.conv.message_func.2.wv.weight\n",
      "Loading layers.0.conv.message_func.2.wsv.weight\n",
      "Loading layers.0.conv.message_func.2.wsv.bias\n",
      "Loading layers.0.norm.0.scalar_norm.weight\n",
      "Loading layers.0.norm.0.scalar_norm.bias\n",
      "Loading layers.0.norm.1.scalar_norm.weight\n",
      "Loading layers.0.norm.1.scalar_norm.bias\n",
      "Loading layers.0.dropout.0.vdropout.dummy_param\n",
      "Loading layers.0.dropout.1.vdropout.dummy_param\n",
      "Loading layers.0.ff_func.0.dummy_param\n",
      "Loading layers.0.ff_func.0.wh.weight\n",
      "Loading layers.0.ff_func.0.ws.weight\n",
      "Loading layers.0.ff_func.0.ws.bias\n",
      "Loading layers.0.ff_func.0.wv.weight\n",
      "Loading layers.0.ff_func.0.wsv.weight\n",
      "Loading layers.0.ff_func.0.wsv.bias\n",
      "Loading layers.0.ff_func.1.dummy_param\n",
      "Loading layers.0.ff_func.1.wh.weight\n",
      "Loading layers.0.ff_func.1.ws.weight\n",
      "Loading layers.0.ff_func.1.ws.bias\n",
      "Loading layers.0.ff_func.1.wv.weight\n",
      "Loading layers.0.ff_func.1.wsv.weight\n",
      "Loading layers.0.ff_func.1.wsv.bias\n",
      "Loading layers.1.conv.message_func.0.dummy_param\n",
      "Loading layers.1.conv.message_func.0.wh.weight\n",
      "Loading layers.1.conv.message_func.0.ws.weight\n",
      "Loading layers.1.conv.message_func.0.ws.bias\n",
      "Loading layers.1.conv.message_func.0.wv.weight\n",
      "Loading layers.1.conv.message_func.0.wsv.weight\n",
      "Loading layers.1.conv.message_func.0.wsv.bias\n",
      "Loading layers.1.conv.message_func.1.dummy_param\n",
      "Loading layers.1.conv.message_func.1.wh.weight\n",
      "Loading layers.1.conv.message_func.1.ws.weight\n",
      "Loading layers.1.conv.message_func.1.ws.bias\n",
      "Loading layers.1.conv.message_func.1.wv.weight\n",
      "Loading layers.1.conv.message_func.1.wsv.weight\n",
      "Loading layers.1.conv.message_func.1.wsv.bias\n",
      "Loading layers.1.conv.message_func.2.dummy_param\n",
      "Loading layers.1.conv.message_func.2.wh.weight\n",
      "Loading layers.1.conv.message_func.2.ws.weight\n",
      "Loading layers.1.conv.message_func.2.ws.bias\n",
      "Loading layers.1.conv.message_func.2.wv.weight\n",
      "Loading layers.1.conv.message_func.2.wsv.weight\n",
      "Loading layers.1.conv.message_func.2.wsv.bias\n",
      "Loading layers.1.norm.0.scalar_norm.weight\n",
      "Loading layers.1.norm.0.scalar_norm.bias\n",
      "Loading layers.1.norm.1.scalar_norm.weight\n",
      "Loading layers.1.norm.1.scalar_norm.bias\n",
      "Loading layers.1.dropout.0.vdropout.dummy_param\n",
      "Loading layers.1.dropout.1.vdropout.dummy_param\n",
      "Loading layers.1.ff_func.0.dummy_param\n",
      "Loading layers.1.ff_func.0.wh.weight\n",
      "Loading layers.1.ff_func.0.ws.weight\n",
      "Loading layers.1.ff_func.0.ws.bias\n",
      "Loading layers.1.ff_func.0.wv.weight\n",
      "Loading layers.1.ff_func.0.wsv.weight\n",
      "Loading layers.1.ff_func.0.wsv.bias\n",
      "Loading layers.1.ff_func.1.dummy_param\n",
      "Loading layers.1.ff_func.1.wh.weight\n",
      "Loading layers.1.ff_func.1.ws.weight\n",
      "Loading layers.1.ff_func.1.ws.bias\n",
      "Loading layers.1.ff_func.1.wv.weight\n",
      "Loading layers.1.ff_func.1.wsv.weight\n",
      "Loading layers.1.ff_func.1.wsv.bias\n"
     ]
    }
   ],
   "source": [
    "def load(model, path):\n",
    "    # this only initializes the gnn with pretrained wweights for first 2 layers.\n",
    "    params = torch.load(path)\n",
    "    state_dict = model.state_dict()\n",
    "    for name, p in params.items():\n",
    "        if name in state_dict and \\\n",
    "               name[:8] in ['layers.0', 'layers.1'] and \\\n",
    "               state_dict[name].shape == p.shape:\n",
    "            print(\"Loading\", name)\n",
    "            model.state_dict()[name].copy_(p)\n",
    "\n",
    "def get_model(task):\n",
    "    return {\n",
    "        'RES' : gvp.atom3d.RESModel,\n",
    "    }[task]()\n",
    "\n",
    "\n",
    "load_path = '/n/groups/marks/users/david/res/model_save/RES_1638990570.3313198_32.pt'\n",
    "\n",
    "model = get_model('RES').to(device)\n",
    "load(model, load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "080d5164-acdb-4cf4-a455-474983c50d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74334it [2:48:21,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.3937415707285245\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_metrics():\n",
    "    return {'accuracy': metrics.accuracy}\n",
    "\n",
    "def test(model, testset, model_path):\n",
    "    #model.load_state_dict(torch.load(args.test))\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    model.eval()\n",
    "    t = tqdm.tqdm(testset)\n",
    "    metrics = get_metrics()\n",
    "    targets, predicts, ids = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in t:\n",
    "            pred = forward(model, batch, device)\n",
    "            label = get_label(batch, 'RES', None)\n",
    "            pred = pred.argmax(dim=-1)\n",
    "\n",
    "            targets.extend(list(label.cpu().numpy()))\n",
    "            predicts.extend(list(pred.cpu().numpy()))\n",
    "\n",
    "    for name, func in metrics.items():\n",
    "\n",
    "        value = func(targets, predicts)\n",
    "        print(f\"{name}: {value}\")\n",
    "\n",
    "test_path = '/n/groups/marks/users/david/res/model_save/RES_1638990570.3313198_32.pt'\n",
    "\n",
    "test(model, testset, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1275cd9c-89be-473e-9528-76ded6e149eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.99543196: : 8it [00:03,  2.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fd33defe5697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-97b16448d668>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainset, valset)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{model_save_path}/RES_{model_id}_{epoch}.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-97b16448d668>\u001b[0m in \u001b[0;36mloop\u001b[0;34m(dataset, model, optimizer, max_time)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, trainset, valset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0c69c5-195a-4275-aca5-e34e1d76dbe2",
   "metadata": {},
   "source": [
    "# evaluate one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5dd91e-7d1c-47df-9590-795f8f1961a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[4885, 3], edge_index=[2, 75300], atoms=[4885], edge_s=[75300, 16], edge_v=[75300, 1, 3], label=[8], ca_idx=[8], batch=[4885], ptr=[9])\n",
      "torch.Size([8, 20])\n",
      "tensor([[-0.0790,  0.0710,  0.0800,  0.0177,  0.1705,  0.0948, -0.0083,  0.0108,\n",
      "         -0.0270,  0.0615,  0.0171,  0.0041,  0.0731,  0.0400,  0.0094,  0.0365,\n",
      "         -0.1175, -0.0768, -0.0051, -0.0794],\n",
      "        [-0.0865,  0.1662, -0.0075, -0.0152,  0.2250,  0.1340, -0.0011,  0.0296,\n",
      "          0.0376,  0.0513,  0.0471,  0.0281,  0.0631,  0.0414,  0.0320,  0.0798,\n",
      "         -0.0887, -0.1366, -0.0847, -0.0250],\n",
      "        [-0.0836,  0.0540,  0.0403,  0.0193,  0.1484,  0.0747, -0.0473,  0.0288,\n",
      "         -0.0489, -0.0130, -0.0221, -0.0369,  0.0947,  0.0056, -0.0653,  0.1089,\n",
      "         -0.0889, -0.1099, -0.0373, -0.1150],\n",
      "        [-0.0770,  0.1295,  0.0805, -0.0212,  0.1863,  0.1097,  0.0389,  0.0483,\n",
      "         -0.0256,  0.0233, -0.0051, -0.0077,  0.0711,  0.0072,  0.0035,  0.0318,\n",
      "         -0.0786, -0.1463,  0.0223, -0.0726],\n",
      "        [-0.0411,  0.0716, -0.0715,  0.0472,  0.1422,  0.0287, -0.0638, -0.0584,\n",
      "         -0.0151,  0.0098, -0.0354, -0.0589,  0.0625, -0.0360, -0.0534,  0.0294,\n",
      "         -0.1039, -0.0687, -0.0106, -0.1198],\n",
      "        [-0.1015,  0.1063,  0.0827, -0.0618,  0.1554,  0.0657, -0.0069,  0.0524,\n",
      "          0.0339,  0.0862,  0.0088, -0.0962,  0.1091, -0.0221, -0.0350,  0.0445,\n",
      "         -0.0728, -0.1081, -0.1163,  0.0244],\n",
      "        [-0.1283,  0.0720,  0.0507,  0.0057,  0.1835,  0.1236,  0.0799, -0.0438,\n",
      "         -0.0132,  0.0522, -0.0199, -0.0597,  0.0191, -0.0105,  0.0435,  0.1054,\n",
      "         -0.0534, -0.1180, -0.0341,  0.0012],\n",
      "        [-0.1299,  0.1692,  0.0521, -0.0054,  0.2110,  0.1490,  0.0086, -0.0145,\n",
      "         -0.0553, -0.0101,  0.0129, -0.0347,  0.0137, -0.0203, -0.0263,  0.0333,\n",
      "         -0.1520, -0.1181, -0.0241, -0.0338]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward>)\n",
      "DataBatch(x=[3575, 3], edge_index=[2, 52392], atoms=[3575], edge_s=[52392, 16], edge_v=[52392, 1, 3], label=[8], ca_idx=[8], batch=[3575], ptr=[9])\n",
      "torch.Size([8, 20])\n",
      "tensor([[-0.0979,  0.1084,  0.0462, -0.0231,  0.1641,  0.1596,  0.0280,  0.0173,\n",
      "         -0.0034, -0.0032, -0.0094,  0.0325,  0.1049, -0.0075,  0.0130,  0.0239,\n",
      "         -0.0338, -0.1586, -0.0725, -0.0777],\n",
      "        [-0.1372,  0.1155,  0.0376,  0.0063,  0.2403,  0.1346,  0.0169, -0.0392,\n",
      "          0.0038,  0.0042, -0.0767,  0.0069,  0.0406,  0.0331,  0.0470,  0.0138,\n",
      "         -0.1369, -0.0593, -0.1233, -0.0413],\n",
      "        [-0.1033,  0.1568,  0.0400, -0.0270,  0.1916,  0.0819,  0.0264, -0.0041,\n",
      "          0.0070,  0.0503,  0.0291, -0.0056,  0.0988,  0.0035, -0.0077,  0.0543,\n",
      "         -0.0747, -0.1069, -0.0838, -0.0600],\n",
      "        [-0.1234,  0.1018, -0.0244, -0.0297,  0.1560, -0.0227,  0.0707,  0.0104,\n",
      "          0.0580,  0.0946,  0.0120, -0.0112,  0.0611,  0.0522,  0.0219,  0.0089,\n",
      "         -0.0676, -0.0562, -0.0864, -0.0392],\n",
      "        [-0.0965,  0.0692, -0.0006,  0.0436,  0.1934,  0.1104, -0.0025, -0.0628,\n",
      "         -0.0560,  0.0109, -0.0018, -0.0208,  0.1023, -0.0707, -0.0458,  0.0575,\n",
      "         -0.0813, -0.1264, -0.0701, -0.0638],\n",
      "        [-0.1730,  0.0884,  0.0526, -0.0563,  0.1684,  0.2124,  0.0301,  0.0529,\n",
      "          0.0406,  0.0059, -0.0211, -0.1384,  0.1179, -0.0162, -0.0095,  0.0584,\n",
      "         -0.0763, -0.1848, -0.0320, -0.0713],\n",
      "        [-0.0915,  0.1378,  0.1129,  0.0305,  0.1677,  0.0479,  0.0076,  0.0237,\n",
      "         -0.0404,  0.0488,  0.0574,  0.0446,  0.1383,  0.0239,  0.0193,  0.0848,\n",
      "         -0.0810, -0.0987, -0.0924,  0.0010],\n",
      "        [-0.1414,  0.1641,  0.0213,  0.0257,  0.1444,  0.1055,  0.0521,  0.0068,\n",
      "          0.0048,  0.0648,  0.0590,  0.0038,  0.0718, -0.0481,  0.0246,  0.0167,\n",
      "         -0.0705, -0.0888, -0.0910, -0.0331]], device='cuda:0',\n",
      "       grad_fn=<IndexBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0a76eeba70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0a76eeba70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0a76eeba70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f0a76eeba70>AssertionError\n",
      "Traceback (most recent call last):\n",
      ": can only test a child process\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0a76eeba70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    if w.is_alive():\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "        assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "self._shutdown_workers()AssertionError: \n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():can only test a child process\n",
      "\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7f0a76eeba70>\n",
      "\n",
      "AssertionError: Traceback (most recent call last):\n",
      "can only test a child process\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0a76eeba70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f0a76eeba70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for b in testset:\n",
    "    if c<2:\n",
    "        print(b)\n",
    "        out = forward(model, b, device)\n",
    "        print(out.shape)\n",
    "        print(out)\n",
    "        c+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865caeb5-7112-4a6b-9442-b3cd9210434e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32e0e903-3e64-4184-8750-b1784d2cc27d",
   "metadata": {},
   "source": [
    "# misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72f5559d-4b2c-4b8d-b8a4-187a9a6e16de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--num-workers N] [--smp-idx IDX]\n",
      "                             [--lba-split SPLIT] [--batch SIZE]\n",
      "                             [--train-time MINUTES] [--val-time MINUTES]\n",
      "                             [--epochs N] [--test PATH] [--lr RATE]\n",
      "                             [--load PATH]\n",
      "                             TASK\n",
      "ipykernel_launcher.py: error: argument TASK: invalid choice: '/home/dd128/.local/share/jupyter/runtime/kernel-970b75c3-b998-4365-a189-164295414e77.json' (choose from 'PSR', 'RSR', 'PPI', 'RES', 'MSP', 'SMP', 'LBA', 'LEP')\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1787, in parse_known_args\n",
      "    namespace, args = self._parse_known_args(args, namespace)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1996, in _parse_known_args\n",
      "    stop_index = consume_positionals(start_index)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1952, in consume_positionals\n",
      "    take_action(action, args)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1845, in take_action\n",
      "    argument_values = self._get_values(action, argument_strings)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 2377, in _get_values\n",
      "    self._check_value(action, value)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 2433, in _check_value\n",
      "    raise ArgumentError(action, msg % args)\n",
      "argparse.ArgumentError: argument TASK: invalid choice: '/home/dd128/.local/share/jupyter/runtime/kernel-970b75c3-b998-4365-a189-164295414e77.json' (choose from 'PSR', 'RSR', 'PPI', 'RES', 'MSP', 'SMP', 'LBA', 'LEP')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-79f9289d065f>\", line 29, in <module>\n",
      "    args = parser.parse_args()\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1755, in parse_args\n",
      "    args, argv = self.parse_known_args(args, namespace)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 1794, in parse_known_args\n",
      "    self.error(str(err))\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 2508, in error\n",
      "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\", line 2495, in exit\n",
      "    _sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m             \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_UNRECOGNIZED_ARGS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   1995\u001b[0m         \u001b[0;31m# consume any positionals following the last Optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1996\u001b[0;31m         \u001b[0mstop_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsume_positionals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mconsume_positionals\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   1951\u001b[0m                 \u001b[0mstart_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0marg_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m                 \u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mtake_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mseen_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1845\u001b[0;31m             \u001b[0margument_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margument_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2376\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36m_check_value\u001b[0;34m(self, action, value)\u001b[0m\n\u001b[1;32m   2432\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid choice: %(value)r (choose from %(choices)s)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2433\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument TASK: invalid choice: '/home/dd128/.local/share/jupyter/runtime/kernel-970b75c3-b998-4365-a189-164295414e77.json' (choose from 'PSR', 'RSR', 'PPI', 'RES', 'MSP', 'SMP', 'LBA', 'LEP')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-79f9289d065f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1793\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2507\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2495\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2053\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m   2054\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0;32m-> 2055\u001b[0;31m                                                                      value))\n\u001b[0m\u001b[1;32m   2056\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[1;32m    632\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                 + out_list)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# from gvp-pytorch: run_atom3d.py\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('task', metavar='TASK', choices=[\n",
    "        'PSR', 'RSR', 'PPI', 'RES', 'MSP', 'SMP', 'LBA', 'LEP'\n",
    "    ], help=\"{PSR, RSR, PPI, RES, MSP, SMP, LBA, LEP}\")\n",
    "parser.add_argument('--num-workers', metavar='N', type=int, default=4,\n",
    "                   help='number of threads for loading data, default=4')\n",
    "parser.add_argument('--smp-idx', metavar='IDX', type=int, default=None,\n",
    "                   choices=list(range(20)),\n",
    "                   help='label index for SMP, in range 0-19')\n",
    "parser.add_argument('--lba-split', metavar='SPLIT', type=int, choices=[30, 60],\n",
    "                    help='identity cutoff for LBA, 30 (default) or 60', default=30)\n",
    "parser.add_argument('--batch', metavar='SIZE', type=int, default=8,\n",
    "                    help='batch size, default=8')\n",
    "parser.add_argument('--train-time', metavar='MINUTES', type=int, default=120,\n",
    "                    help='maximum time between evaluations on valset, default=120 minutes')\n",
    "parser.add_argument('--val-time', metavar='MINUTES', type=int, default=20,\n",
    "                    help='maximum time per evaluation on valset, default=20 minutes')\n",
    "parser.add_argument('--epochs', metavar='N', type=int, default=50,\n",
    "                    help='training epochs, default=50')\n",
    "parser.add_argument('--test', metavar='PATH', default=None,\n",
    "                    help='evaluate a trained model')\n",
    "parser.add_argument('--lr', metavar='RATE', default=1e-4, type=float,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--load', metavar='PATH', default=None, \n",
    "                    help='initialize first 2 GNN layers with pretrained weights')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    datasets = get_datasets(args.task, args.lba_split)\n",
    "    dataloader = partial(torch_geometric.data.DataLoader, \n",
    "                    num_workers=args.num_workers, batch_size=args.batch)\n",
    "    if args.task not in ['PPI', 'RES']:\n",
    "        dataloader = partial(dataloader, shuffle=True)\n",
    "        \n",
    "    trainset, valset, testset = map(dataloader, datasets)    \n",
    "    model = get_model(args.task).to(device)\n",
    "    \n",
    "    if args.test:\n",
    "        test(model, testset)\n",
    "\n",
    "    else:\n",
    "        if args.load:\n",
    "            load(model, args.load)\n",
    "        train(model, trainset, valset)\n",
    "        \n",
    "def test(model, testset):\n",
    "    model.load_state_dict(torch.load(args.test))\n",
    "    model.eval()\n",
    "    t = tqdm.tqdm(testset)\n",
    "    metrics = get_metrics(args.task)\n",
    "    targets, predicts, ids = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in t:\n",
    "            pred = forward(model, batch, device)\n",
    "            label = get_label(batch, args.task, args.smp_idx)\n",
    "            if args.task == 'RES':\n",
    "                pred = pred.argmax(dim=-1)\n",
    "            if args.task in ['PSR', 'RSR']:\n",
    "                ids.extend(batch.id)\n",
    "            targets.extend(list(label.cpu().numpy()))\n",
    "            predicts.extend(list(pred.cpu().numpy()))\n",
    "\n",
    "    for name, func in metrics.items():\n",
    "        if args.task in ['PSR', 'RSR']:\n",
    "            func = partial(func, ids=ids)\n",
    "        value = func(targets, predicts)\n",
    "        print(f\"{name}: {value}\")\n",
    "\n",
    "def train(model, trainset, valset):\n",
    "                                \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    best_path, best_val = None, np.inf\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        loss = loop(trainset, model, optimizer=optimizer, max_time=args.train_time)\n",
    "        path = f\"{models_dir}/{args.task}_{model_id}_{epoch}.pt\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f'\\nEPOCH {epoch} TRAIN loss: {loss:.8f}')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss = loop(valset, model, max_time=args.val_time)\n",
    "        print(f'\\nEPOCH {epoch} VAL loss: {loss:.8f}')\n",
    "        if loss < best_val:\n",
    "            best_path, best_val = path, loss\n",
    "        print(f'BEST {best_path} VAL loss: {best_val:.8f}')\n",
    "    \n",
    "def loop(dataset, model, optimizer=None, max_time=None):\n",
    "    start = time.time()\n",
    "    \n",
    "    loss_fn = get_loss(args.task)\n",
    "    t = tqdm.tqdm(dataset)\n",
    "    total_loss, total_count = 0, 0\n",
    "    \n",
    "    for batch in t:\n",
    "        if max_time and (time.time() - start) > 60*max_time: break\n",
    "        if optimizer: optimizer.zero_grad()\n",
    "        try:\n",
    "            out = forward(model, batch, device)\n",
    "        except RuntimeError as e:\n",
    "            if \"CUDA out of memory\" not in str(e): raise(e)\n",
    "            torch.cuda.empty_cache()\n",
    "            print('Skipped batch due to OOM', flush=True)\n",
    "            continue\n",
    "            \n",
    "        label = get_label(batch, args.task, args.smp_idx)\n",
    "        loss_value = loss_fn(out, label)\n",
    "        total_loss += float(loss_value)\n",
    "        total_count += 1\n",
    "        \n",
    "        if optimizer:\n",
    "            try:\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "            except RuntimeError as e:\n",
    "                if \"CUDA out of memory\" not in str(e): raise(e)\n",
    "                torch.cuda.empty_cache()\n",
    "                print('Skipped batch due to OOM', flush=True)\n",
    "                continue\n",
    "            \n",
    "        t.set_description(f\"{total_loss/total_count:.8f}\")\n",
    "        \n",
    "    return total_loss / total_count\n",
    "\n",
    "def load(model, path):\n",
    "    params = torch.load(path)\n",
    "    state_dict = model.state_dict()\n",
    "    for name, p in params.items():\n",
    "        if name in state_dict and \\\n",
    "               name[:8] in ['layers.0', 'layers.1'] and \\\n",
    "               state_dict[name].shape == p.shape:\n",
    "            print(\"Loading\", name)\n",
    "            model.state_dict()[name].copy_(p)\n",
    "        \n",
    "#######################################################################\n",
    "\n",
    "def get_label(batch, task, smp_idx=None):\n",
    "    if type(batch) in [list, tuple]: batch = batch[0]\n",
    "    if task == 'SMP':\n",
    "        assert smp_idx is not None\n",
    "        return batch.label[smp_idx::20]\n",
    "    return batch.label\n",
    "\n",
    "def get_metrics(task):\n",
    "    def _correlation(metric, targets, predict, ids=None, glob=True):\n",
    "        if glob: return metric(targets, predict)\n",
    "        _targets, _predict = defaultdict(list), defaultdict(list)\n",
    "        for _t, _p, _id in zip(targets, predict, ids):\n",
    "            _targets[_id].append(_t)\n",
    "            _predict[_id].append(_p)\n",
    "        return np.mean([metric(_targets[_id], _predict[_id]) for _id in _targets])\n",
    "        \n",
    "    correlations = {\n",
    "        'pearson': partial(_correlation, metrics.pearson),\n",
    "        'kendall': partial(_correlation, metrics.kendall),\n",
    "        'spearman': partial(_correlation, metrics.spearman)\n",
    "    }\n",
    "    mean_correlations = {f'mean {k}' : partial(v, glob=False) \\\n",
    "                            for k, v in correlations.items()}\n",
    "    \n",
    "    return {                       \n",
    "        'RSR' : {**correlations, **mean_correlations},\n",
    "        'PSR' : {**correlations, **mean_correlations},\n",
    "        'PPI' : {'auroc': metrics.auroc},\n",
    "        'RES' : {'accuracy': metrics.accuracy},\n",
    "        'MSP' : {'auroc': metrics.auroc, 'auprc': metrics.auprc},\n",
    "        'LEP' : {'auroc': metrics.auroc, 'auprc': metrics.auprc},\n",
    "        'LBA' : {**correlations, 'rmse': partial(sk_metrics.mean_squared_error, squared=False)},\n",
    "        'SMP' : {'mae': sk_metrics.mean_absolute_error}\n",
    "    }[task]\n",
    "            \n",
    "def get_loss(task):\n",
    "    if task in ['PSR', 'RSR', 'SMP', 'LBA']: return nn.MSELoss() # regression\n",
    "    elif task in ['PPI', 'MSP', 'LEP']: return nn.BCELoss() # binary classification\n",
    "    elif task in ['RES']: return nn.CrossEntropyLoss() # multiclass classification\n",
    "    \n",
    "def forward(model, batch, device):\n",
    "    if type(batch) in [list, tuple]:\n",
    "        batch = batch[0].to(device), batch[1].to(device)\n",
    "    else:\n",
    "        batch = batch.to(device)\n",
    "    return model(batch)\n",
    "\n",
    "def get_datasets(task, lba_split=30):\n",
    "    data_path = {\n",
    "        'RES' : 'atom3d-data/RES/raw/RES/data/',\n",
    "        'PPI' : 'atom3d-data/PPI/splits/DIPS-split/data/',\n",
    "        'RSR' : 'atom3d-data/RSR/splits/candidates-split-by-time/data/',\n",
    "        'PSR' : 'atom3d-data/PSR/splits/split-by-year/data/',\n",
    "        'MSP' : 'atom3d-data/MSP/splits/split-by-sequence-identity-30/data/',\n",
    "        'LEP' : 'atom3d-data/LEP/splits/split-by-protein/data/',\n",
    "        'LBA' : f'atom3d-data/LBA/splits/split-by-sequence-identity-{lba_split}/data/',\n",
    "        'SMP' : 'atom3d-data/SMP/splits/random/data/'\n",
    "    }[task]\n",
    "        \n",
    "    if task == 'RES':\n",
    "        split_path = 'atom3d-data/RES/splits/split-by-cath-topology/indices/'\n",
    "        dataset = partial(gvp.atom3d.RESDataset, data_path)        \n",
    "        trainset = dataset(split_path=split_path+'train_indices.txt')\n",
    "        valset = dataset(split_path=split_path+'val_indices.txt')\n",
    "        testset = dataset(split_path=split_path+'test_indices.txt')\n",
    "    \n",
    "    elif task == 'PPI':\n",
    "        trainset = gvp.atom3d.PPIDataset(data_path+'train')\n",
    "        valset = gvp.atom3d.PPIDataset(data_path+'val')\n",
    "        testset = gvp.atom3d.PPIDataset(data_path+'test')\n",
    "        \n",
    "    else:\n",
    "        transform = {                       \n",
    "            'RSR' : gvp.atom3d.RSRTransform,\n",
    "            'PSR' : gvp.atom3d.PSRTransform,\n",
    "            'MSP' : gvp.atom3d.MSPTransform,\n",
    "            'LEP' : gvp.atom3d.LEPTransform,\n",
    "            'LBA' : gvp.atom3d.LBATransform,\n",
    "            'SMP' : gvp.atom3d.SMPTransform,\n",
    "        }[task]()\n",
    "        \n",
    "        trainset = LMDBDataset(data_path+'train', transform=transform)\n",
    "        valset = LMDBDataset(data_path+'val', transform=transform)\n",
    "        testset = LMDBDataset(data_path+'test', transform=transform)\n",
    "        \n",
    "    return trainset, valset, testset\n",
    "\n",
    "def get_model(task):\n",
    "    return {\n",
    "        'RES' : gvp.atom3d.RESModel,\n",
    "    }[task]()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a04fc-7118-4ab2-8732-c9f60a8b684d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

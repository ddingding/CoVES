{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4595916f-26f1-4cc4-9e94-ea50831803b0",
   "metadata": {},
   "source": [
    "# code for sampling from evcouplings model\n",
    "\n",
    "- simulated annealing code written by Nathan Rollins.\n",
    "- modified to suit toxin antitoxin by David Ding.\n",
    "\n",
    "### Inputs:\n",
    "- evCouplings model\n",
    "\n",
    "### Outputs:\n",
    "- sampled sequences at defined antitoxin positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43e54a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evcouplings.couplings import CouplingsModel\n",
    "from evcouplings.couplings.model import _single_mutant_hamiltonians\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import viz_seqs\n",
    "%matplotlib inline\n",
    "\n",
    "dout = './samples/'\n",
    "fin_evc_model = \"./parED_e1_3_m80_f80.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1bfb59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming(seq1,seq2):\n",
    "    assert len(seq1) == len(seq2)\n",
    "    h = 0\n",
    "    for aa1,aa2 in zip(seq1,seq2):\n",
    "        if aa1!=aa2:\n",
    "            h+=1\n",
    "    return h\n",
    "\n",
    "class EVHannealer():\n",
    "    '''optimize a focus sequence (uppercase only) according to statistical enery'''\n",
    "    def __init__(self, model_file):\n",
    "        self.model = CouplingsModel(model_file)\n",
    "        self.L = len(self.model.index_list)\n",
    "        self.AA = len(self.model.alphabet)\n",
    "        \n",
    "    def encode(self,seq):\n",
    "        '''convert sequence to integer vector'''\n",
    "        seq_vector = self.model.convert_sequences([seq])[0]\n",
    "        return seq_vector\n",
    "    \n",
    "    def decode(self,seq_vector):\n",
    "        '''convert integer vector to sequence'''\n",
    "        seq = ''.join([self.model.alphabet[i] for i in seq_vector])\n",
    "        return seq\n",
    "    \n",
    "    def random_seq_vector(self):\n",
    "        seq_vector = np.array([np.random.choice(np.arange(len(self.model.alphabet)))\n",
    "                               for i in range(len(self.model.target_seq))])\n",
    "        return seq_vector\n",
    "    \n",
    "    def residuelist_to_mask(self,position_list,amino_acid_list):\n",
    "        '''for listed positions, mask=1 for listed amino acid'''\n",
    "        mask = np.zeros((self.L,self.AA))\n",
    "        assert len(position_list) == len(amino_acid_list)\n",
    "        for i,aa in zip(position_list,amino_acid_list):\n",
    "            mask[self.model.index_map[i],self.model.alphabet_map[aa]] = 1.0\n",
    "        return mask.astype(bool)\n",
    "        \n",
    "        \n",
    "    def residuelist_to_negative_sitemask(self,position_list,amino_acid_list):\n",
    "        '''for listed positions, mask=1 for amino acids mismatching listed amino acid'''\n",
    "        mask = np.zeros((self.L,self.AA))\n",
    "        assert len(position_list) == len(amino_acid_list)\n",
    "        for i,aa in zip(position_list,amino_acid_list):\n",
    "            mask[self.model.index_map[i],:] = 1.0\n",
    "            mask[self.model.index_map[i],self.model.alphabet_map[aa]] = 0.0\n",
    "        return mask.astype(bool)\n",
    "    \n",
    "    def get_hamming_matrix_fxn(self, target_focus_sequence, min_hamming, max_hamming, weight=10):\n",
    "        '''create a fxn that favors match if hamming > max,\n",
    "            penalizes match if hamming < min'''\n",
    "        target_seq_vector = self.encode(target_focus_sequence)\n",
    "        target_seq_mask = self.residuelist_to_mask(self.model.index_list,target_focus_sequence)\n",
    "        penalty_well = lambda h: -weight*(h<=min_hamming) + weight*(h>=max_hamming)\n",
    "        x = np.arange(min_hamming-5,max_hamming+5)\n",
    "        plt.plot(x, np.vectorize(penalty_well)(x))\n",
    "        plt.gcf().set_size_inches(3,3)\n",
    "        \n",
    "        mask_fxn = lambda seq_vector: (\n",
    "            penalty_well(hamming(target_seq_vector, seq_vector))\n",
    "            * target_seq_mask\n",
    "            )\n",
    "        return mask_fxn\n",
    "        \n",
    "        \n",
    "    def mutate_seq(self, seq, residue_list, amino_acid_list):\n",
    "        mseq = list(seq)\n",
    "        for i,aa in zip(residue_list,amino_acid_list):\n",
    "            mseq[self.model.index_map[i]] = aa\n",
    "        return mseq\n",
    "    \n",
    "    def mutate_seq_vector(self, seq_vector, residue_list, amino_acid_list):\n",
    "        mseq = deepcopy(seq_vector)\n",
    "        for i,aa in zip(residue_list,amino_acid_list):\n",
    "            mseq[self.model.index_map[i]] = self.model.alphabet_map[aa]\n",
    "        return mseq\n",
    "        \n",
    "        \n",
    "    def step(self,seq_vector,T,force_mutation=False,avoid_mask=None, penalty_matrix=None):\n",
    "        '''introduce a mutation with boltzmann probability\n",
    "        higher temperature = closer to uniform distribution'''\n",
    "        EVH = _single_mutant_hamiltonians(seq_vector, self.model.J_ij, self.model.h_i)[:,:,0]\n",
    "        E = deepcopy(EVH)\n",
    "        if penalty_matrix is not None:\n",
    "            E += penalty_matrix(seq_vector)\n",
    "        \n",
    "        P = np.exp(E/T)\n",
    "        if avoid_mask is not None:\n",
    "            P[avoid_mask(seq_vector)] = 0.0\n",
    "    \n",
    "        P = P/np.sum(P)\n",
    "            \n",
    "        P_flat = P.ravel()\n",
    "        indices = np.arange(len(P_flat))\n",
    "        mutation_index = np.random.choice(indices, p=P_flat)\n",
    "        mutation_i, mutation_aa = np.unravel_index(mutation_index, P.shape)\n",
    "        mut_vector = deepcopy(seq_vector)\n",
    "        mut_vector[mutation_i] = mutation_aa\n",
    "        mutation_EVH = EVH[mutation_i, mutation_aa]\n",
    "        mutation_E = E[mutation_i, mutation_aa]\n",
    "        previous_aa = seq_vector[mutation_i]\n",
    "\n",
    "        return mut_vector, mutation_i, mutation_aa, previous_aa, mutation_EVH, mutation_E\n",
    "        \n",
    "\n",
    "def make_annealed_samples(t_correction, distance_penalty):\n",
    "    # Start with a random sequence\n",
    "    start_seq_vector = annealer.random_seq_vector()\n",
    "    sample_seq_vector = deepcopy(start_seq_vector)\n",
    "    # Set any fixed positions to fixed AA values\n",
    "    sample_seq_vector = annealer.mutate_seq_vector(\n",
    "        sample_seq_vector,fixed_pos,fixed_wt_aa\n",
    "    )\n",
    "\n",
    "    # Set temperature cycle for annealing\n",
    "    L = int(len(start_seq_vector))\n",
    "    T_cycle = [1.0*t_correction]*L + [0.5*t_correction]*L + [0.2*t_correction]*L\n",
    "\n",
    "    # Record progress during annealing\n",
    "    annealing_report = []\n",
    "    for n,T in enumerate(T_cycle):\n",
    "        sample_seq_vector, mut_i, mut_aa, prev_aa, mut_EVH, mut_E = annealer.step(\n",
    "            sample_seq_vector,\n",
    "            T,\n",
    "            penalty_matrix = distance_penalty,\n",
    "            avoid_mask = lambda x: fixed_position_mask\n",
    "        )\n",
    "\n",
    "        annealing_report.append([sample_seq_vector, mut_i, mut_aa, prev_aa, mut_EVH, mut_E])\n",
    "\n",
    "    # Make progress report human-readable\n",
    "    annealing_report = pd.DataFrame(annealing_report, columns=['seq_vector','n_i','n_aa_mut','n_aa_prev','delta_EVH','delta_E'])\n",
    "    annealing_report.loc[:,'i'] = annealing_report.n_i.apply(lambda n: annealer.model.index_list[n])\n",
    "    annealing_report.loc[:,'aa_prev'] = annealing_report.n_aa_prev.apply(lambda n: annealer.model.alphabet[n])\n",
    "    annealing_report.loc[:,'aa_mut'] = annealing_report.n_aa_mut.apply(lambda n: annealer.model.alphabet[n])\n",
    "\n",
    "    # Calculate EVH scores (annealer returns delta EVHs)\n",
    "    target_seq = annealer.model.target_seq\n",
    "    scores = annealer.model.hamiltonians(np.array(list(annealing_report.seq_vector)))\n",
    "    annealing_report.loc[:,'E']  = scores[:,0]\n",
    "    annealing_report.loc[:,'Eh'] = scores[:,1]\n",
    "    annealing_report.loc[:,'Ej'] = scores[:,2]\n",
    "    annealing_report.loc[:,'E-Ewt'] = annealing_report['E'] - annealer.model.hamiltonians([target_seq])[0,0]\n",
    "\n",
    "    # Compare sequences to EVH model target sequence\n",
    "    annealing_report.loc[:,'seq'] = annealing_report.seq_vector.apply(annealer.decode)\n",
    "    annealing_report.loc[:,'Nmuts'] = annealing_report.seq.apply(lambda x: sum(a!=b for a,b in zip(target_seq,x)))\n",
    "\n",
    "\n",
    "    wt_seq = ''.join(c.seq())\n",
    "\n",
    "    def get_muts(mut_seq):\n",
    "        mut_str = ':'.join([v_wt +str(pos-offset)+ v_mut for pos,v_wt, v_mut in zip(c.index_list, c.seq(), mut_seq) if v_wt != v_mut])\n",
    "        return mut_str\n",
    "\n",
    "    annealing_report['muts'] = annealing_report.apply(lambda r: get_muts(r.seq), axis=1)\n",
    "\n",
    "\n",
    "    wt_muts = 'L48L:D52D:I53I:R55R:L56L:F74F:R78R:E80E:A81A:R82R'\n",
    "\n",
    "    def make_full_mut(wt_muts, mut_muts):\n",
    "        # expecting something like mut_muts = 'D52E:I53V:F74M:R78K'\n",
    "        # and wt_muts = 'L48L:D52D:I53I:R55R:L56L:F74F:R78R:E80E:A81A:R82R'\n",
    "        # and make the full wt muts\n",
    "        dic_wt_muts = dict(\n",
    "            zip([v[:-1] for v in wt_muts.split(':')],\n",
    "                wt_muts.split(':')\n",
    "               )\n",
    "                 )\n",
    "        dic_mut_muts = dict(\n",
    "            zip([v[:-1] for v in mut_muts.split(':')],\n",
    "                mut_muts.split(':')\n",
    "               )\n",
    "                 )\n",
    "\n",
    "        full_muts = []\n",
    "        for k,v in dic_wt_muts.items():\n",
    "            if k in dic_mut_muts:\n",
    "                full_muts.append(dic_mut_muts[k])\n",
    "            else:\n",
    "                full_muts.append(v)\n",
    "\n",
    "        return ':'.join(full_muts)\n",
    "\n",
    "    annealing_report['full_mut'] = annealing_report.apply(lambda r: make_full_mut(wt_muts, r.muts), axis=1)\n",
    "\n",
    "\n",
    "    # Preview the table\n",
    "    #annealing_report.iloc[[0,1,2,-3,-2,-1]]\n",
    "    return annealing_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754a8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load EVH annealer and couplingsmodel\n",
    "annealer = EVHannealer(fin_evc_model)\n",
    "\n",
    "# load parameters from file to create a pairwise model\n",
    "c = CouplingsModel(fin_evc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc937ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L48L 151\n",
      "L48L not uppercase in couplingsmodel\n",
      "D52D 155\n",
      "129\n",
      "I53I 156\n",
      "130\n",
      "R55R 158\n",
      "132\n",
      "L56L 159\n",
      "133\n",
      "F74F 177\n",
      "151\n",
      "R78R 181\n",
      "155\n",
      "E80E 183\n",
      "157\n",
      "A81A 184\n",
      "158\n",
      "R82R 185\n",
      "159\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "# inspect which positions can be sampled in evcouplings\n",
    "\n",
    "fixed_pos = list(c.index_list)\n",
    "fixed_wt_aa = list(c.seq())\n",
    "\n",
    "offset = 103\n",
    "\n",
    "wt_muts = 'L48L:D52D:I53I:R55R:L56L:F74F:R78R:E80E:A81A:R82R'\n",
    "\n",
    "\n",
    "idxs_to_remove = [] # make a list of indices to be removed from the fixed position list of uppercase indices and wt_aa to be fixed.\n",
    "for m in wt_muts.split(':'):\n",
    "    wt_aa = m[0]\n",
    "    mut_pos = int(m[1:-1])\n",
    "    mut_aa = m[-1]\n",
    "    \n",
    "    complex_mut_pos = offset + mut_pos\n",
    "    print(m, complex_mut_pos)\n",
    "    if complex_mut_pos in c.index_list:\n",
    "        assert wt_aa == c.seq(complex_mut_pos) \n",
    "        \n",
    "        to_remove_idx = list(c.index_list).index(complex_mut_pos)\n",
    "        idxs_to_remove.append(to_remove_idx)\n",
    "        \n",
    "        print(to_remove_idx)\n",
    "        \n",
    "    else:\n",
    "        print(m, 'not uppercase in couplingsmodel')\n",
    "\n",
    "fixed_pos = [i for j, i in enumerate(fixed_pos) if j not in idxs_to_remove]\n",
    "fixed_wt_aa = [i for j, i in enumerate(fixed_wt_aa) if j not in idxs_to_remove]\n",
    "\n",
    "assert len(fixed_pos) == len(fixed_wt_aa)\n",
    "\n",
    "print(len(fixed_pos))\n",
    "\n",
    "# fix all non-mutated positions apart from AT L48, which is lowercase (not enough column coverage)\n",
    "fixed_position_mask = annealer.residuelist_to_negative_sitemask(\n",
    "    fixed_pos,fixed_wt_aa\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d719a2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidding/anaconda3/envs/tf_env/lib/python3.7/site-packages/ipykernel_launcher.py:87: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "# sample at vaying temperatures\n",
    "for t in [1e-2, 1e-1, 1, 2,3,5,10]:\n",
    "    df_anneal_t = make_annealed_samples(t, distance_penalty=None)\n",
    "    df_anneal_t.to_csv(dout+ 't_screen/' + 'df_anneal_{}.csv'.format(t))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ffc198-963b-4dd9-9db7-63a1bb597e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verify that pytorch-geometric is correctly installed\n",
    "import torch_geometric\n",
    "import torch_sparse\n",
    "from torch_geometric.nn import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a2b4a1-a099-4ad0-88e1-885babc096f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import esm\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca83b259-19ff-42dc-8fb5-3e6a87635784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/pretrained.py:175: UserWarning: Regression weights not found, predicting contacts will not produce correct results.\n",
      "  \"Regression weights not found, predicting contacts will not produce correct results.\"\n"
     ]
    }
   ],
   "source": [
    "model, alphabet = esm.pretrained.esm_if1_gvp4_t16_142M_UR50()\n",
    "# to get rid of random dropout\n",
    "model= model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a93c72b6-cefe-44fd-b275-70de7ff38289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/biotite/structure/io/pdbx/convert.py:287: UserWarning: Attribute 'auth_seq_id' not found within 'atom_site' category. The fallback attribute 'label_seq_id' will be used instead\n",
      "  UserWarning\n",
      "/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/biotite/structure/io/pdbx/convert.py:287: UserWarning: Attribute 'auth_comp_id' not found within 'atom_site' category. The fallback attribute 'label_comp_id' will be used instead\n",
      "  UserWarning\n",
      "/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/biotite/structure/io/pdbx/convert.py:287: UserWarning: Attribute 'auth_atom_id' not found within 'atom_site' category. The fallback attribute 'label_atom_id' will be used instead\n",
      "  UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average log-likelihood on entire sequence: -1.23 (perplexity 3.42)\n",
      "average log-likelihood excluding missing coordinates: -1.23 (perplexity 3.42)\n",
      "took 9.082840204238892 seconds\n",
      "9000 variants will take 22.70710051059723 hours\n"
     ]
    }
   ],
   "source": [
    "fpath = '/n/groups/marks/users/david/esm_if/data/bio_all_rm_non_chain.cif' # .pdb format is also acceptable\n",
    "coords, seqs = esm.inverse_folding.multichain_util.load_complex_coords(fpath, ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])\n",
    "\n",
    "start_t = time.time() # in seconds\n",
    "ll_fullseq, ll_withcoord = esm.inverse_folding.multichain_util.score_sequence_in_complex(\n",
    "    model, \n",
    "    alphabet,\n",
    "    coords,\n",
    "    'C',\n",
    "    seqs['C']\n",
    ")\n",
    "end_t = time.time()\n",
    "\n",
    "print(f'average log-likelihood on entire sequence: {ll_fullseq:.2f} (perplexity {np.exp(-ll_fullseq):.2f})')\n",
    "print(f'average log-likelihood excluding missing coordinates: {ll_withcoord:.2f} (perplexity {np.exp(-ll_withcoord):.2f})')\n",
    "time_taken = end_t - start_t\n",
    "print('took {} seconds'.format(time_taken))\n",
    "print('9000 variants will take {} hours'.format(9000*time_taken/60/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbdc169-7508-4c54-beba-30eba8bbb1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "304e6461-5899-49a6-9022-9b8f6c67fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/n/groups/marks/users/david/esm_if/data/seq_to_score/'+ 'df_mut_chris_no_stop.csv')\n",
    "df_test = df_test[:2]\n",
    "df_test.to_csv('/n/groups/marks/users/david/esm_if/data/seq_to_score/df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f26bfc7-8c94-449c-89e3-128def75e4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>seq</th>\n",
       "      <th>conservation</th>\n",
       "      <th>inter</th>\n",
       "      <th>intra</th>\n",
       "      <th>fit</th>\n",
       "      <th>muts</th>\n",
       "      <th>full_mut</th>\n",
       "      <th>stop</th>\n",
       "      <th>muts_m1</th>\n",
       "      <th>mut_seq_chC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ALAL</td>\n",
       "      <td>-237.603375</td>\n",
       "      <td>-31.439403</td>\n",
       "      <td>-80.617306</td>\n",
       "      <td>-0.001478</td>\n",
       "      <td>ALAL</td>\n",
       "      <td>L58A:W59L:D60A:K63L</td>\n",
       "      <td>False</td>\n",
       "      <td>L59A:W60L:D61A:K64L</td>\n",
       "      <td>ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ALAE</td>\n",
       "      <td>-236.936851</td>\n",
       "      <td>-31.011770</td>\n",
       "      <td>-80.474616</td>\n",
       "      <td>0.015735</td>\n",
       "      <td>ALAE</td>\n",
       "      <td>L58A:W59L:D60A:K63E</td>\n",
       "      <td>False</td>\n",
       "      <td>L59A:W60L:D61A:K64E</td>\n",
       "      <td>ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   seq  conservation      inter      intra       fit  muts  \\\n",
       "0           0  ALAL   -237.603375 -31.439403 -80.617306 -0.001478  ALAL   \n",
       "1           1  ALAE   -236.936851 -31.011770 -80.474616  0.015735  ALAE   \n",
       "\n",
       "              full_mut   stop              muts_m1  \\\n",
       "0  L58A:W59L:D60A:K63L  False  L59A:W60L:D61A:K64L   \n",
       "1  L58A:W59L:D60A:K63E  False  L59A:W60L:D61A:K64E   \n",
       "\n",
       "                                         mut_seq_chC  \n",
       "0  ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...  \n",
       "1  ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('/n/groups/marks/users/david/esm_if/data/seq_to_score/df_test.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca9a045-3dbf-4567-8e14-fdadf7776e9b",
   "metadata": {},
   "source": [
    "# to test the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5fbbf0b-7284-4af7-8170-7b632179b9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_mut</th>\n",
       "      <th>E3</th>\n",
       "      <th>V5L</th>\n",
       "      <th>A66F</th>\n",
       "      <th>D55E</th>\n",
       "      <th>V75C</th>\n",
       "      <th>N99V</th>\n",
       "      <th>R100W</th>\n",
       "      <th>E87M</th>\n",
       "      <th>A66I</th>\n",
       "      <th>V5L/D55E</th>\n",
       "      <th>V5L/A66F</th>\n",
       "      <th>E2</th>\n",
       "      <th>stop</th>\n",
       "      <th>muts_m1</th>\n",
       "      <th>mut_seq_chC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D60A:K63A:E79A</td>\n",
       "      <td>0.658741</td>\n",
       "      <td>0.924719</td>\n",
       "      <td>0.926970</td>\n",
       "      <td>0.877962</td>\n",
       "      <td>0.783168</td>\n",
       "      <td>0.747125</td>\n",
       "      <td>1.048427</td>\n",
       "      <td>0.967851</td>\n",
       "      <td>0.930315</td>\n",
       "      <td>1.012619</td>\n",
       "      <td>0.955635</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>False</td>\n",
       "      <td>D61A:K64A:E80A</td>\n",
       "      <td>ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D60A:K63A:E79C</td>\n",
       "      <td>0.532164</td>\n",
       "      <td>0.861220</td>\n",
       "      <td>0.938649</td>\n",
       "      <td>0.817779</td>\n",
       "      <td>0.719811</td>\n",
       "      <td>0.681587</td>\n",
       "      <td>0.930138</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.891346</td>\n",
       "      <td>0.990992</td>\n",
       "      <td>0.921711</td>\n",
       "      <td>0.178514</td>\n",
       "      <td>False</td>\n",
       "      <td>D61A:K64A:E80C</td>\n",
       "      <td>ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D60A:K63A:E79D</td>\n",
       "      <td>0.458571</td>\n",
       "      <td>0.895409</td>\n",
       "      <td>0.931136</td>\n",
       "      <td>0.797239</td>\n",
       "      <td>0.559013</td>\n",
       "      <td>0.565601</td>\n",
       "      <td>0.984797</td>\n",
       "      <td>0.948527</td>\n",
       "      <td>0.915542</td>\n",
       "      <td>0.980943</td>\n",
       "      <td>0.992542</td>\n",
       "      <td>-0.037274</td>\n",
       "      <td>False</td>\n",
       "      <td>D61A:K64A:E80D</td>\n",
       "      <td>ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D60A:K63A:E79E</td>\n",
       "      <td>0.850977</td>\n",
       "      <td>0.955051</td>\n",
       "      <td>0.987775</td>\n",
       "      <td>0.961778</td>\n",
       "      <td>0.951983</td>\n",
       "      <td>0.890569</td>\n",
       "      <td>0.943179</td>\n",
       "      <td>0.961443</td>\n",
       "      <td>0.990926</td>\n",
       "      <td>0.988444</td>\n",
       "      <td>1.043746</td>\n",
       "      <td>0.105763</td>\n",
       "      <td>False</td>\n",
       "      <td>D61A:K64A:E80E</td>\n",
       "      <td>ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D60A:K63A:E79F</td>\n",
       "      <td>0.609473</td>\n",
       "      <td>0.897230</td>\n",
       "      <td>0.942582</td>\n",
       "      <td>0.841820</td>\n",
       "      <td>0.743454</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>0.941937</td>\n",
       "      <td>0.939176</td>\n",
       "      <td>0.910273</td>\n",
       "      <td>1.019961</td>\n",
       "      <td>0.941611</td>\n",
       "      <td>0.140926</td>\n",
       "      <td>False</td>\n",
       "      <td>D61A:K64A:E80F</td>\n",
       "      <td>ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D60A:K63A:E79G</td>\n",
       "      <td>0.139403</td>\n",
       "      <td>0.688930</td>\n",
       "      <td>0.634135</td>\n",
       "      <td>0.410260</td>\n",
       "      <td>0.200918</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>0.963007</td>\n",
       "      <td>0.733209</td>\n",
       "      <td>0.632592</td>\n",
       "      <td>0.923859</td>\n",
       "      <td>0.930863</td>\n",
       "      <td>0.068116</td>\n",
       "      <td>False</td>\n",
       "      <td>D61A:K64A:E80G</td>\n",
       "      <td>ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D60A:K63A:E79H</td>\n",
       "      <td>0.585224</td>\n",
       "      <td>0.883803</td>\n",
       "      <td>0.931893</td>\n",
       "      <td>0.890580</td>\n",
       "      <td>0.692569</td>\n",
       "      <td>0.695369</td>\n",
       "      <td>0.936409</td>\n",
       "      <td>0.947056</td>\n",
       "      <td>0.888949</td>\n",
       "      <td>0.997133</td>\n",
       "      <td>0.948960</td>\n",
       "      <td>0.211568</td>\n",
       "      <td>False</td>\n",
       "      <td>D61A:K64A:E80H</td>\n",
       "      <td>ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D60A:K63A:E79I</td>\n",
       "      <td>0.785455</td>\n",
       "      <td>0.929819</td>\n",
       "      <td>0.956014</td>\n",
       "      <td>0.889507</td>\n",
       "      <td>0.870191</td>\n",
       "      <td>0.864626</td>\n",
       "      <td>0.953175</td>\n",
       "      <td>0.968640</td>\n",
       "      <td>0.954402</td>\n",
       "      <td>0.988256</td>\n",
       "      <td>0.980690</td>\n",
       "      <td>0.261156</td>\n",
       "      <td>False</td>\n",
       "      <td>D61A:K64A:E80I</td>\n",
       "      <td>ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         full_mut        E3       V5L      A66F      D55E      V75C      N99V  \\\n",
       "0  D60A:K63A:E79A  0.658741  0.924719  0.926970  0.877962  0.783168  0.747125   \n",
       "1  D60A:K63A:E79C  0.532164  0.861220  0.938649  0.817779  0.719811  0.681587   \n",
       "2  D60A:K63A:E79D  0.458571  0.895409  0.931136  0.797239  0.559013  0.565601   \n",
       "3  D60A:K63A:E79E  0.850977  0.955051  0.987775  0.961778  0.951983  0.890569   \n",
       "4  D60A:K63A:E79F  0.609473  0.897230  0.942582  0.841820  0.743454  0.739003   \n",
       "5  D60A:K63A:E79G  0.139403  0.688930  0.634135  0.410260  0.200918  0.131363   \n",
       "6  D60A:K63A:E79H  0.585224  0.883803  0.931893  0.890580  0.692569  0.695369   \n",
       "7  D60A:K63A:E79I  0.785455  0.929819  0.956014  0.889507  0.870191  0.864626   \n",
       "\n",
       "      R100W      E87M      A66I  V5L/D55E  V5L/A66F        E2   stop  \\\n",
       "0  1.048427  0.967851  0.930315  1.012619  0.955635  0.216500  False   \n",
       "1  0.930138  0.953372  0.891346  0.990992  0.921711  0.178514  False   \n",
       "2  0.984797  0.948527  0.915542  0.980943  0.992542 -0.037274  False   \n",
       "3  0.943179  0.961443  0.990926  0.988444  1.043746  0.105763  False   \n",
       "4  0.941937  0.939176  0.910273  1.019961  0.941611  0.140926  False   \n",
       "5  0.963007  0.733209  0.632592  0.923859  0.930863  0.068116  False   \n",
       "6  0.936409  0.947056  0.888949  0.997133  0.948960  0.211568  False   \n",
       "7  0.953175  0.968640  0.954402  0.988256  0.980690  0.261156  False   \n",
       "\n",
       "          muts_m1                                        mut_seq_chC  \n",
       "0  D61A:K64A:E80A  ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...  \n",
       "1  D61A:K64A:E80C  ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...  \n",
       "2  D61A:K64A:E80D  ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...  \n",
       "3  D61A:K64A:E80E  ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...  \n",
       "4  D61A:K64A:E80F  ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...  \n",
       "5  D61A:K64A:E80G  ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...  \n",
       "6  D61A:K64A:E80H  ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...  \n",
       "7  D61A:K64A:E80I  ANVEKMSVAVTPQQAAVMREAVEAGEYATASEIVREAVRDWLAKRE...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_score[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "468a0d13-af48-4924-8d52-9b57fad495b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "writing to /n/groups/marks/users/david/esm_if/data/seq_to_score/df_mut_all_no_stop_scores_test_ipy2.csv\n",
      "loading model in\n",
      "reading structure in\n",
      "starting to score\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.456486940383911 seconds, total hrs expected to complete:0.03182357483439975\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.801580429077148 seconds, total hrs expected to complete:0.03278216785854764\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.720196008682251 seconds, total hrs expected to complete:0.032556100024117365\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.749638557434082 seconds, total hrs expected to complete:0.03263788488176134\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.826601266860962 seconds, total hrs expected to complete:0.03285167018572489\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.576789379119873 seconds, total hrs expected to complete:0.03215774827533298\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.618051290512085 seconds, total hrs expected to complete:0.032272364695866904\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.559518814086914 seconds, total hrs expected to complete:0.03210977448357476\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.775125980377197 seconds, total hrs expected to complete:0.03270868327882555\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.65226411819458 seconds, total hrs expected to complete:0.03236740032831828\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 116] Stale file handle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-109c2bc43f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'one it of scoring took {} seconds, total hrs expected to complete:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit_time\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_to_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 116] Stale file handle"
     ]
    }
   ],
   "source": [
    "# this isn't writing the output to file\n",
    "import esm\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "models_dir = 'models'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_id = float(time.time())\n",
    "print(device)\n",
    "\n",
    "\n",
    "# batch score\n",
    "datapath = '/n/groups/marks/users/david/esm_if/data/seq_to_score/'\n",
    "#print(sys.argv)\n",
    "#f_name = sys.argv[1]\n",
    "f_name = 'df_mut_all_no_stop.csv'\n",
    "\n",
    "pout = datapath + f_name.rstrip('.csv') + '_scores_test_ipy2.csv'\n",
    "print('writing to {}'.format(pout))\n",
    "df_to_score = pd.read_csv(datapath+ f_name)\n",
    "\n",
    "df_to_score = df_to_score[:10]\n",
    "\n",
    "print('loading model in')\n",
    "# load model\n",
    "model, alphabet = esm.pretrained.esm_if1_gvp4_t16_142M_UR50()\n",
    "# to get rid of random dropout\n",
    "model= model.eval()\n",
    "\n",
    "print('reading structure in')\n",
    "# read structure in \n",
    "cifpath = '/n/groups/marks/users/david/esm_if/data/bio_all_rm_non_chain.cif' # .pdb format is also acceptable\n",
    "coords, seqs = esm.inverse_folding.multichain_util.load_complex_coords(\n",
    "    cifpath, \n",
    "    ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    ")\n",
    "\n",
    "with open(pout, 'w') as fout:\n",
    "    print('starting to score')\n",
    "    for n,r in df_to_score.iterrows():\n",
    "        print('scoring one...')\n",
    "        mut_str = r.muts_m1\n",
    "        seq_to_score = r.mut_seq_chC\n",
    "        \n",
    "        start = time.time()\n",
    "        print('start scoring')\n",
    "        ll_fullseq, ll_withcoord = esm.inverse_folding.multichain_util.score_sequence_in_complex(\n",
    "            model, \n",
    "            alphabet,\n",
    "            coords,\n",
    "            'C',\n",
    "            seq_to_score\n",
    "        )\n",
    "        write_line = ','.join([mut_str, seq_to_score, str(ll_fullseq), str(ll_withcoord)]) + '\\n'\n",
    "        #print(write_line)\n",
    "        fout.write(write_line)\n",
    "        end = time.time()\n",
    "        it_time = end- start\n",
    "        print('one it of scoring took {} seconds, total hrs expected to complete:{}'.format(it_time, it_time * len(df_to_score)/60/60))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9738dee3-e85b-4b3a-a2de-2f9d30c7036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "writing to /n/groups/marks/users/david/esm_if/data/seq_to_score/df_mut_all_no_stop_scores_test_ipy3.csv\n",
      "loading model in\n",
      "reading structure in\n",
      "starting to score\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.53757381439209 seconds, total hrs expected to complete:0.03204881615108914\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 12.005290508270264 seconds, total hrs expected to complete:0.033348029189639625\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.570830821990967 seconds, total hrs expected to complete:0.03214119672775269\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.875778436660767 seconds, total hrs expected to complete:0.032988273435168795\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.592339038848877 seconds, total hrs expected to complete:0.03220094177458021\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.812720537185669 seconds, total hrs expected to complete:0.032813112603293525\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.756637811660767 seconds, total hrs expected to complete:0.03265732725461324\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.800949335098267 seconds, total hrs expected to complete:0.032780414819717406\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.574172735214233 seconds, total hrs expected to complete:0.03215047982003954\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.807080030441284 seconds, total hrs expected to complete:0.032797444529003565\n"
     ]
    }
   ],
   "source": [
    "# open the file and keep open\n",
    "\n",
    "import esm\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "models_dir = 'models'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_id = float(time.time())\n",
    "print(device)\n",
    "\n",
    "\n",
    "# batch score\n",
    "datapath = '/n/groups/marks/users/david/esm_if/data/seq_to_score/'\n",
    "#print(sys.argv)\n",
    "#f_name = sys.argv[1]\n",
    "f_name = 'df_mut_all_no_stop.csv'\n",
    "\n",
    "pout = datapath + f_name.rstrip('.csv') + '_scores_test_ipy3.csv'\n",
    "print('writing to {}'.format(pout))\n",
    "df_to_score = pd.read_csv(datapath+ f_name)\n",
    "\n",
    "df_to_score = df_to_score[:10]\n",
    "\n",
    "print('loading model in')\n",
    "# load model\n",
    "model, alphabet = esm.pretrained.esm_if1_gvp4_t16_142M_UR50()\n",
    "# to get rid of random dropout\n",
    "model= model.eval()\n",
    "\n",
    "print('reading structure in')\n",
    "# read structure in \n",
    "cifpath = '/n/groups/marks/users/david/esm_if/data/bio_all_rm_non_chain.cif' # .pdb format is also acceptable\n",
    "coords, seqs = esm.inverse_folding.multichain_util.load_complex_coords(\n",
    "    cifpath, \n",
    "    ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    ")\n",
    "\n",
    "list_write = []\n",
    "print('starting to score')\n",
    "for n,r in df_to_score.iterrows():\n",
    "    print('scoring one...')\n",
    "    mut_str = r.muts_m1\n",
    "    seq_to_score = r.mut_seq_chC\n",
    "\n",
    "    start = time.time()\n",
    "    print('start scoring')\n",
    "    ll_fullseq, ll_withcoord = esm.inverse_folding.multichain_util.score_sequence_in_complex(\n",
    "        model, \n",
    "        alphabet,\n",
    "        coords,\n",
    "        'C',\n",
    "        seq_to_score\n",
    "    )\n",
    "    write_line = ','.join([mut_str, seq_to_score, str(ll_fullseq), str(ll_withcoord)]) #+ '\\n'\n",
    "    list_write.append(write_line)\n",
    "    end = time.time()\n",
    "    it_time = end- start\n",
    "    print('one it of scoring took {} seconds, total hrs expected to complete:{}'.format(it_time, it_time * len(df_to_score)/60/60))\n",
    "    fout = open(pout, 'w')\n",
    "    fout.write('\\n'.join(list_write))\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51070623-c958-4211-9f27-98b37e073361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "writing to /n/groups/marks/users/david/esm_if/data/seq_to_score/df_704_10x_exp_no_stop_scores.csv\n",
      "loading model in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/pretrained.py:175: UserWarning: Regression weights not found, predicting contacts will not produce correct results.\n",
      "  \"Regression weights not found, predicting contacts will not produce correct results.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading structure in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/biotite/structure/io/pdbx/convert.py:287: UserWarning: Attribute 'auth_seq_id' not found within 'atom_site' category. The fallback attribute 'label_seq_id' will be used instead\n",
      "  UserWarning\n",
      "/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/biotite/structure/io/pdbx/convert.py:287: UserWarning: Attribute 'auth_comp_id' not found within 'atom_site' category. The fallback attribute 'label_comp_id' will be used instead\n",
      "  UserWarning\n",
      "/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/biotite/structure/io/pdbx/convert.py:287: UserWarning: Attribute 'auth_atom_id' not found within 'atom_site' category. The fallback attribute 'label_atom_id' will be used instead\n",
      "  UserWarning\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import esm\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "models_dir = 'models'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_id = float(time.time())\n",
    "print(device)\n",
    "\n",
    "\n",
    "# batch score\n",
    "datapath = '/n/groups/marks/users/david/esm_if/data/seq_to_score/'\n",
    "#print(sys.argv)\n",
    "#f_name = sys.argv[1]\n",
    "f_name = 'df_704_10x_exp_no_stop.csv'\n",
    "\n",
    "pout = datapath + f_name.rstrip('.csv') + '_scores.csv'\n",
    "print('writing to {}'.format(pout))\n",
    "df_to_score = pd.read_csv(datapath+ f_name)\n",
    "\n",
    "#df_to_score = df_to_score[:10]\n",
    "\n",
    "print('loading model in')\n",
    "# load model\n",
    "model, alphabet = esm.pretrained.esm_if1_gvp4_t16_142M_UR50()\n",
    "# to get rid of random dropout\n",
    "model= model.eval()\n",
    "\n",
    "print('reading structure in')\n",
    "# read structure in \n",
    "cifpath = '/n/groups/marks/users/david/esm_if/data/bio_all_rm_non_chain.cif' # .pdb format is also acceptable\n",
    "coords, seqs = esm.inverse_folding.multichain_util.load_complex_coords(\n",
    "    cifpath, \n",
    "    ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e5d50e-9da3-4afe-898b-fe8f6d6fe24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_write = []\n",
    "muts_done = {}\n",
    "# read in all the lines that have already been done\n",
    "f_done = open(pout, 'r')\n",
    "for l in f_done:\n",
    "    list_write.append(l.rstrip('\\n'))\n",
    "    mut_m1 = l.split(',')[0]\n",
    "    muts_done[mut_m1] = 1\n",
    "#print(list_write)\n",
    "f_done.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c6adae3-ca05-44a8-ad6d-6145de7c02d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to score\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 12.747006893157959 seconds, total hrs expected to complete:19.768483190139136\n",
      "just scored L48L:D52D:I53I:R55R:L56L:F74A:R78R:E80F:A81A:R82R\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 12.08551025390625 seconds, total hrs expected to complete:18.73925506591797\n",
      "just scored L48L:D52D:I53I:R55R:L56L:F74R:R78Q:E80S:A81I:R82L\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.318896293640137 seconds, total hrs expected to complete:17.547433393001555\n",
      "just scored L48L:D52D:I53I:R55R:L56L:F74L:R78S:E80S:A81Q:R82F\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.229236602783203 seconds, total hrs expected to complete:17.405316734313963\n",
      "just scored L48L:D52D:I53I:R55R:L56L:F74R:R78K:E80R:A81H:R82V\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 11.435964822769165 seconds, total hrs expected to complete:17.71939216150178\n",
      "just scored L48L:D52D:I53I:R55R:L56L:F74F:R78L:E80I:A81I:R82L\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 10.778469800949097 seconds, total hrs expected to complete:16.697646133303643\n",
      "just scored L48L:D52D:I53I:R55R:L56L:F74S:R78S:E80V:A81L:R82D\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 10.432145118713379 seconds, total hrs expected to complete:16.15823366165161\n",
      "just scored L48L:D52D:I53I:R55R:L56L:F74R:R78T:E80Y:A81R:R82K\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 10.389920473098755 seconds, total hrs expected to complete:16.089946288201546\n",
      "just scored L48D:D52A:I53E:R55V:L56E:F74F:R78R:E80E:A81A:R82R\n",
      "scoring one...\n",
      "start scoring\n",
      "one it of scoring took 10.124702453613281 seconds, total hrs expected to complete:15.676414299011231\n",
      "just scored L48L:D52D:I53I:R55R:L56L:F74I:R78E:E80L:A81S:R82C\n",
      "scoring one...\n",
      "start scoring\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-32bfb2fa4848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mseq_to_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         )\n\u001b[1;32m     19\u001b[0m         \u001b[0mwrite_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmut_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_to_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mll_fullseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mll_withcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ '\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/inverse_folding/multichain_util.py\u001b[0m in \u001b[0;36mscore_sequence_in_complex\u001b[0;34m(model, alphabet, coords, target_chain_id, target_seq, padding_length)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     loss, target_padding_mask = get_sequence_loss(model, alphabet, all_coords,\n\u001b[0;32m--> 127\u001b[0;31m             target_seq)\n\u001b[0m\u001b[1;32m    128\u001b[0m     ll_fullseq = -np.sum(loss * ~target_padding_mask) / np.sum(\n\u001b[1;32m    129\u001b[0m             ~target_padding_mask)\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/inverse_folding/util.py\u001b[0m in \u001b[0;36mget_sequence_loss\u001b[0;34m(model, alphabet, coords, seq)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mtarget_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_output_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/inverse_folding/gvp_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, coords, padding_mask, confidence, prev_output_tokens, return_all_hiddens, features_only)\u001b[0m\n\u001b[1;32m     77\u001b[0m     ):\n\u001b[1;32m     78\u001b[0m         encoder_out = self.encoder(coords, padding_mask, confidence,\n\u001b[0;32m---> 79\u001b[0;31m             return_all_hiddens=return_all_hiddens)\n\u001b[0m\u001b[1;32m     80\u001b[0m         logits, extra = self.decoder(\n\u001b[1;32m     81\u001b[0m             \u001b[0mprev_output_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/inverse_folding/gvp_transformer_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, coords, encoder_padding_mask, confidence, return_all_hiddens)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[1;32m    154\u001b[0m         x, encoder_embedding = self.forward_embedding(coords,\n\u001b[0;32m--> 155\u001b[0;31m                 encoder_padding_mask, confidence)\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;31m# account for padding while computing the representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mencoder_padding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/inverse_folding/gvp_transformer_encoder.py\u001b[0m in \u001b[0;36mforward_embedding\u001b[0;34m(self, coords, padding_mask, confidence)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# GVP encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         gvp_out_scalars, gvp_out_vectors = self.gvp_encoder(coords,\n\u001b[0;32m---> 92\u001b[0;31m                 coord_mask, padding_mask, confidence)\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rotation_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# Rotate to local rotation frame for rotation-invariance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/inverse_folding/gvp_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, coords, coord_mask, padding_mask, confidence)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             node_embeddings, edge_embeddings = layer(node_embeddings,\n\u001b[0;32m---> 53\u001b[0;31m                     edge_index, edge_embeddings)\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mnode_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munflatten_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/inverse_folding/gvp_modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, autoregressive_x, node_mask)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/inverse_folding/gvp_modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m    303\u001b[0m         message = self.propagate(edge_index, \n\u001b[1;32m    304\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                     edge_attr=edge_attr)\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                         \u001b[0mmsg_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmsg_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/inverse_folding/gvp_modules.py\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, s_i, v_i, s_j, v_j, edge_attr)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mv_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple_cat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/esm/inverse_folding/gvp_modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mvn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_norm_no_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_act\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/groups/marks/software/anaconda_o2/envs/dd_torch/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print('starting to score')\n",
    "c = 0\n",
    "for n,r in df_to_score.iterrows():\n",
    "    mut_str = r.muts_m1\n",
    "    \n",
    "    if mut_str not in muts_done:\n",
    "        print('scoring one...')\n",
    "        seq_to_score = r.mut_seq_chC\n",
    "\n",
    "        start = time.time()\n",
    "        print('start scoring')\n",
    "        ll_fullseq, ll_withcoord = esm.inverse_folding.multichain_util.score_sequence_in_complex(\n",
    "            model, \n",
    "            alphabet,\n",
    "            coords,\n",
    "            'C',\n",
    "            seq_to_score\n",
    "        )\n",
    "        write_line = ','.join([mut_str, seq_to_score, str(ll_fullseq), str(ll_withcoord)]) #+ '\\n'\n",
    "        list_write.append(write_line)\n",
    "        end = time.time()\n",
    "        it_time = end- start\n",
    "        print('one it of scoring took {} seconds, total hrs expected to complete:{}'.format(it_time, it_time * (len(df_to_score)-c)/60/60))\n",
    "        print('just scored {}'.format(mut_str))\n",
    "\n",
    "        fout = open(pout, 'w')\n",
    "        fout.write('\\n'.join(list_write))\n",
    "        fout.close()\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6393b0a-342f-46ea-871c-6f667b0e1900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-1.9-gpu)",
   "language": "python",
   "name": "pytorch-1.9-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
